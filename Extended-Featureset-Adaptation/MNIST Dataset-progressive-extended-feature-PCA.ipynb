{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "try:\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "except Exception as ex:        \n",
    "    from six.moves import urllib\n",
    "    from scipy.io import loadmat\n",
    "    import os\n",
    "\n",
    "    mnist_path = os.path.join(\".\", \"datasets\", \"mnist-original.mat\")\n",
    "\n",
    "    # download dataset from github.\n",
    "    mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "    response = urllib.request.urlopen(mnist_alternative_url)\n",
    "    with open(mnist_path, \"wb\") as f:\n",
    "        content = response.read()\n",
    "        f.write(content)\n",
    "\n",
    "    mnist_raw = loadmat(mnist_path)\n",
    "    mnist = {\n",
    "        \"data\": mnist_raw[\"data\"].T,\n",
    "        \"target\": mnist_raw[\"label\"][0],\n",
    "        \"COL_NAMES\": [\"label\", \"data\"],\n",
    "        \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
    "    }\n",
    "    print(\"Done!\")\n",
    "\n",
    "X = mnist.data / 255.0\n",
    "y = mnist.target\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 784) (21000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49000, 500), (21000, 500))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataset with only 500 features out of 784\n",
    "feature_set = 500\n",
    "X_train_reduced = X_train[:,:feature_set]\n",
    "X_test_reduced = X_test[:,:feature_set]\n",
    "X_train_reduced.shape, X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['select']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "input_dim = 500\n",
    "output_dim = 10\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 43\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 64\n",
    "epochs_per_task = 10\n",
    "\n",
    "n_stats = 1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[7,9],[3,8],[0,6],[4,2]]\n",
    "#task_labels = [[8,9], [6,7], [4,5], [2,3], [0,1]]\n",
    "#task_labels = [[0,9], [7,8], [3,6], [1,4], [2,5]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8,9]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9]]\n",
    "n_tasks = len(task_labels)\n",
    "nb_classes  = 10\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=feature_set)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_train, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_train_reduced[idx], np_utils.to_categorical(label_map[Y_train[idx]], len(labels))\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_train[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(label_map[Y_train[idx]], len(labels))\n",
    "    else:\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_train_reduced[idx], np_utils.to_categorical(Y_train[idx], nb_classes)\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_train[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(Y_train[idx], nb_classes)\n",
    "        training_datasets.append(data)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_test, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_test_reduced[idx], np_utils.to_categorical(label_map[Y_test[idx]], len(labels))\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_test[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(label_map[Y_test[idx]], len(labels))\n",
    "    else:\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_test_reduced[idx], np_utils.to_categorical(Y_test[idx], nb_classes)\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_test[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(Y_test[idx], nb_classes)\n",
    "        validation_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import keras.backend as K\n",
    "import keras.activations as activations\n",
    "\n",
    "output_mask = tf.Variable(tf.zeros(output_dim), name=\"mask\", trainable=False)\n",
    "\n",
    "def masked_softmax(logits):\n",
    "    # logits are [batch_size, output_dim]\n",
    "    x = select(tf.tile(tf.equal(output_mask[None, :], 1.0), [tf.shape(logits)[0], 1]), logits, -1e32 * tf.ones_like(logits))\n",
    "    return activations.softmax(x)\n",
    "\n",
    "def set_active_outputs(labels):\n",
    "    new_mask = np.zeros(output_dim)\n",
    "    for l in labels:\n",
    "        new_mask[l] = 1.0\n",
    "    sess.run(output_mask.assign(new_mask))\n",
    "    print(sess.run(output_mask))\n",
    "    \n",
    "def masked_predict(model, data, targets):\n",
    "    pred = model.predict(data)\n",
    "    print(pred)\n",
    "    acc = np.argmax(pred,1)==np.argmax(targets,1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn, input_shape=(input_dim,)))\n",
    "#model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn))\n",
    "#model.add(Dense(n_hidden_units, activation=activation_fn))\n",
    "model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax))\n",
    "\n",
    "from pathint import protocols\n",
    "from pathint.optimizers import KOOptimizer\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.callbacks import Callback\n",
    "from pathint.keras_utils import LossHistory\n",
    "\n",
    "#protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "#protocol_name, protocol = protocols.FISHER_PROTOCOL('sum')\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#opt = SGD(1e-3)\n",
    "#opt = RMSprop(lr=1e-3)\n",
    "oopt = KOOptimizer(opt, model=model, **protocol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=oopt, metrics=['accuracy'])\n",
    "model.model._make_train_function()\n",
    "saved_weights = model.get_weights()\n",
    "\n",
    "history = LossHistory()\n",
    "callbacks = [history]\n",
    "datafile_name = \"split_mnist_data_%s.pkl.gz\"%protocol_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_fits(cvals, training_data, valid_data, eval_on_train_set=False, nstats=1):\n",
    "    acc_mean = dict()\n",
    "    acc_std = dict()\n",
    "    model_weights_save = []   #Empty list to save the model weights aftertraining each task\n",
    "    for cidx, cval_ in enumerate(tqdm(cvals)):\n",
    "        runs = []\n",
    "        for runid in range(nstats):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # model.set_weights(saved_weights)\n",
    "            cstuffs = []\n",
    "            evals = []\n",
    "            print(\"setting cval\")\n",
    "            cval = cval_\n",
    "            oopt.set_strength(cval)\n",
    "            oopt.init_task_vars()\n",
    "            print(\"cval is\", sess.run(oopt.lam))\n",
    "            for age, tidx in enumerate(range(n_tasks)):\n",
    "                print(\"Age %i, cval is=%f\"%(age,cval))\n",
    "                print(\"settint output mask\")\n",
    "                set_active_outputs(task_labels[age])\n",
    "                stuffs = model.fit(training_data[tidx][0], training_data[tidx][1], batch_size, epochs_per_task, callbacks=callbacks)\n",
    "                oopt.update_task_metrics(training_data[tidx][0], training_data[tidx][1], batch_size)\n",
    "                oopt.update_task_vars()\n",
    "                ftask = []\n",
    "                model_weights_save.append(model.get_weights()) #Save the model weights aftertraining each task\n",
    "                for j in range(n_tasks):\n",
    "                    set_active_outputs(task_labels[j])\n",
    "                    if eval_on_train_set:\n",
    "                        f_ = masked_predict(model, training_data[j][0], training_data[j][1])\n",
    "                    else:\n",
    "                        f_ = masked_predict(model, valid_data[j][0], valid_data[j][1])\n",
    "                    ftask.append(np.mean(f_))\n",
    "                evals.append(ftask)\n",
    "                cstuffs.append(stuffs)\n",
    "\n",
    "                # Re-initialize optimizater variables\n",
    "                if reset_optimizer:\n",
    "                    oopt.reset_optimizer()\n",
    "\n",
    "            evals = np.array(evals)\n",
    "            runs.append(evals)\n",
    "        \n",
    "        runs = np.array(runs)\n",
    "        acc_mean[cval_] = runs.mean(0)\n",
    "        acc_std[cval_] = runs.std(0)\n",
    "    return dict(mean=acc_mean, std=acc_std),model_weights_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "# cvals = np.concatenate(([0], np.logspace(-2, 2, 10)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-1, 2, 2)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-2, 0, 3)))\n",
    "#cvals = np.logspace(-3, 3, 7)#[0, 1.0, 2, 5, 10]\n",
    "cvals = [1.0]\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 1.0\n",
      "Age 0, cval is=1.000000\n",
      "settint output mask\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0867 - acc: 0.9942     \n",
      "Epoch 2/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0047 - acc: 0.9987     \n",
      "Epoch 3/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0033 - acc: 0.9990     \n",
      "Epoch 4/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0027 - acc: 0.9992     \n",
      "Epoch 5/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0021 - acc: 0.9993     \n",
      "Epoch 6/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0020 - acc: 0.9993     \n",
      "Epoch 7/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0016 - acc: 0.9995     \n",
      "Epoch 8/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0013 - acc: 0.9995      \n",
      "Epoch 9/10\n",
      "10447/10447 [==============================] - 0s - loss: 0.0011 - acc: 0.9996       \n",
      "Epoch 10/10\n",
      "10447/10447 [==============================] - 0s - loss: 9.0935e-04 - acc: 0.9996     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[2.4929002e-04 9.9975067e-01 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999964e-01 3.0723101e-07 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999702e-01 2.9364394e-06 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [9.9838769e-01 1.6123266e-03 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999988e-01 7.5475768e-08 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 8.5662466e-10 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.5148721  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.52276677 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.51625866 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.5321271  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.515463   ... 0.         0.         0.        ]\n",
      " [0.         0.         0.5370508  ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0.         0.         0.         ... 0.4902704  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.5094706  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.5268773  0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.49937612 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.48862264 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.51827615 0.         0.        ]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0.         0.         0.         ... 0.         0.49448013 0.50551987]\n",
      " [0.         0.         0.         ... 0.         0.5141854  0.48581454]\n",
      " [0.         0.         0.         ... 0.         0.5336381  0.4663619 ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.518646   0.48135403]\n",
      " [0.         0.         0.         ... 0.         0.5244734  0.47552666]\n",
      " [0.         0.         0.         ... 0.         0.5055672  0.49443284]]\n",
      "Age 1, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.2046 - acc: 0.9306     \n",
      "Epoch 2/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1412 - acc: 0.9526     \n",
      "Epoch 3/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1289 - acc: 0.9575     \n",
      "Epoch 4/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1219 - acc: 0.9604     \n",
      "Epoch 5/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1193 - acc: 0.9598     \n",
      "Epoch 6/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1132 - acc: 0.9628     \n",
      "Epoch 7/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1154 - acc: 0.9606     \n",
      "Epoch 8/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1092 - acc: 0.9620     \n",
      "Epoch 9/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1073 - acc: 0.9626     \n",
      "Epoch 10/10\n",
      "9893/9893 [==============================] - 0s - loss: 0.1066 - acc: 0.9632     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.1480062e-04 9.9988520e-01 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999940e-01 6.5113835e-07 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999690e-01 3.1462587e-06 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [9.9490297e-01 5.0970586e-03 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999988e-01 8.4432010e-08 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 2.0881126e-09 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.00198974 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00135779 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9611443  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.9154599  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00098725 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.01361729 ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0.         0.         0.         ... 0.48951507 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.50607735 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.52595264 0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.49661788 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.48184094 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.49939474 0.         0.        ]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0.         0.         0.         ... 0.         0.4969863  0.50301373]\n",
      " [0.         0.         0.         ... 0.         0.51494    0.48505998]\n",
      " [0.         0.         0.         ... 0.         0.5308548  0.46914524]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.51938605 0.48061395]\n",
      " [0.         0.         0.         ... 0.         0.5209861  0.47901392]\n",
      " [0.         0.         0.         ... 0.         0.51692456 0.48307547]]\n",
      "Age 2, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "9119/9119 [==============================] - 0s - loss: 0.0970 - acc: 0.9783     \n",
      "Epoch 2/10\n",
      "9119/9119 [==============================] - 0s - loss: 0.0069 - acc: 0.9988     \n",
      "Epoch 3/10\n",
      "9119/9119 [==============================] - 0s - loss: 0.0034 - acc: 0.9998     \n",
      "Epoch 4/10\n",
      "9119/9119 [==============================] - 0s - loss: 0.0022 - acc: 1.0000     \n",
      "Epoch 5/10\n",
      "9119/9119 [==============================] - 0s - loss: 0.0016 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "9119/9119 [==============================] - 0s - loss: 0.0012 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "9119/9119 [==============================] - 0s - loss: 9.5963e-04 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "9119/9119 [==============================] - 0s - loss: 7.8976e-04 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "9119/9119 [==============================] - 0s - loss: 6.5991e-04 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "9119/9119 [==============================] - 0s - loss: 5.6171e-04 - acc: 1.0000     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.1486522e-04 9.9988508e-01 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999940e-01 6.5253329e-07 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999690e-01 3.1460697e-06 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [9.9490744e-01 5.0925091e-03 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999988e-01 8.4434262e-08 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 2.0901010e-09 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.00200031 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00135741 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9611355  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.91549444 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00098733 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.01361706 ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0.         0.         0.         ... 0.4965336  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.57475364 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.5518646  0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5595555  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.4403472  0.         0.        ]\n",
      " [0.         0.         0.         ... 0.49232227 0.         0.        ]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0.         0.         0.         ... 0.         0.47682685 0.5231731 ]\n",
      " [0.         0.         0.         ... 0.         0.53828645 0.4617135 ]\n",
      " [0.         0.         0.         ... 0.         0.64318097 0.35681906]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.52108324 0.47891682]\n",
      " [0.         0.         0.         ... 0.         0.5427857  0.45721424]\n",
      " [0.         0.         0.         ... 0.         0.4587713  0.5412287 ]]\n",
      "Age 3, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Epoch 1/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0599 - acc: 0.9872     \n",
      "Epoch 2/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0221 - acc: 0.9946     \n",
      "Epoch 3/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0192 - acc: 0.9951     \n",
      "Epoch 4/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0174 - acc: 0.9954     \n",
      "Epoch 5/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0157 - acc: 0.9956     \n",
      "Epoch 6/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0149 - acc: 0.9963     \n",
      "Epoch 7/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0143 - acc: 0.9962     \n",
      "Epoch 8/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0129 - acc: 0.9966     \n",
      "Epoch 9/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0133 - acc: 0.9964     \n",
      "Epoch 10/10\n",
      "9871/9871 [==============================] - 0s - loss: 0.0117 - acc: 0.9965     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.1477019e-04 9.9988520e-01 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999940e-01 6.5264783e-07 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999690e-01 3.1432567e-06 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [9.9491560e-01 5.0844154e-03 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9999988e-01 8.4354419e-08 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 2.0887381e-09 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.00200963 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00135419 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.96119386 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.9157224  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.0009864  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.01358613 ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.9995410e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.3539847e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.9996221e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.7832074e-02\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.9994135e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.5525116e-01\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0.         0.         0.         ... 0.         0.48770058 0.5122994 ]\n",
      " [0.         0.         0.         ... 0.         0.54647875 0.45352125]\n",
      " [0.         0.         0.         ... 0.         0.6497124  0.35028768]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.51507753 0.48492253]\n",
      " [0.         0.         0.         ... 0.         0.5466676  0.45333242]\n",
      " [0.         0.         0.         ... 0.         0.4551393  0.54486066]]\n",
      "Age 4, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Epoch 1/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.1895 - acc: 0.9399     \n",
      "Epoch 2/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.1251 - acc: 0.9573     \n",
      "Epoch 3/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.1158 - acc: 0.9592     \n",
      "Epoch 4/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.1108 - acc: 0.9615     \n",
      "Epoch 5/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.1066 - acc: 0.9614     \n",
      "Epoch 6/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.1037 - acc: 0.9626     \n",
      "Epoch 7/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.1013 - acc: 0.9633     \n",
      "Epoch 8/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.0998 - acc: 0.9643     \n",
      "Epoch 9/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.0981 - acc: 0.9648     \n",
      "Epoch 10/10\n",
      "9670/9670 [==============================] - 0s - loss: 0.0967 - acc: 0.9657     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.14715054e-04 9.99885321e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99999285e-01 6.57292503e-07 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99996901e-01 3.15419015e-06 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.94939804e-01 5.06019033e-03 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99999881e-01 8.44516563e-08 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 2.09758522e-09 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.00199537 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00134251 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9613589  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.91581297 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00097905 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.01364873 ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.9995220e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0627684e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.9996281e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.3975430e-02\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.9994576e-01\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.5600224e-01\n",
      "  0.0000000e+00 0.0000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:23<00:00, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  9.96476948e-01 3.52308201e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.85811822e-03 9.98141885e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  9.96873438e-01 3.12659913e-03]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  8.98861587e-01 1.01138346e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  9.99981642e-01 1.83383981e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  8.77536952e-01 1.22463070e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "recompute_data = True\n",
    "\n",
    "if recompute_data:\n",
    "    data,model_weights_save = run_fits(cvals, training_datasets, validation_datasets, eval_on_train_set=False, nstats=n_stats)\n",
    "    utils.save_zipped_pickle(data, datafile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 43)                21543     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                440       \n",
      "=================================================================\n",
      "Total params: 21,983\n",
      "Trainable params: 21,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(500, 43)\n",
      "(43,)\n",
      "(43, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(model.summary())\n",
    "model.save_weights('saved_weights.h5') #This file cannot be opend normaly to view the weghts. It can be loaded through load_model() or can be opend via hdf5 viewer\n",
    "\n",
    "#Shape of the array containg model weights\n",
    "a_list = model.get_weights()\n",
    "for i in range(len(a_list)):\n",
    "    print((np.array(a_list[i])).shape)\n",
    "\n",
    "#a_list[0][0][0] = a_list[0][0][0]+0.00001\n",
    "#print(a_list[0][0][0])\n",
    "#model.set_weights(a_list)\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_zipped_pickle(datafile_name)\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': {1.0: array([[0.99884607, 0.50542709, 0.42906919, 0.48301536, 0.5220034 ],\n",
      "       [0.99884607, 0.96814535, 0.44798407, 0.48627268, 0.53294432],\n",
      "       [0.99884607, 0.96814535, 0.95470383, 0.45416473, 0.68247022],\n",
      "       [0.99884607, 0.96814535, 0.95818815, 0.98557469, 0.67882324],\n",
      "       [0.99884607, 0.96838131, 0.95893479, 0.98557469, 0.94407975]])}, 'std': {1.0: array([[0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.]])}}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.colors as colors\n",
    "cmap = plt.get_cmap('cool') \n",
    "cNorm  = colors.Normalize(vmin=-5, vmax=np.log(np.max(list(data['mean'].keys()))))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "print(scalarMap.get_clim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x180 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(14, 2.5))\n",
    "axs = [subplot(1,n_tasks+1,1)]#, None, None]\n",
    "for i in range(1, n_tasks + 1):\n",
    "    axs.append(subplot(1, n_tasks+1, i+1, sharex=axs[0], sharey=axs[0]))\n",
    "    \n",
    "keys = list(data['mean'].keys())\n",
    "sorted_keys = np.sort(keys)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "        colorVal = scalarMap.to_rgba(np.log(cval))\n",
    "        # axs[j].plot(evals[:, j], c=colorVal)\n",
    "        axs[j].errorbar(range(n_tasks), mean_vals[:, j], yerr=std_vals[:, j]/np.sqrt(n_stats), c=colorVal)\n",
    "    label = \"c=%g\"%cval\n",
    "    average = mean_vals.mean(1)  #Taking the average of cross validation accuracies accross all tasks after learning each task\n",
    "    axs[-1].plot(average, c=colorVal, label=label)\n",
    "    \n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title((['task %d'%j for j in range(n_tasks)] + ['average'])[i])\n",
    "gcf().tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig('MNIST-5Task-Progressive-Transfer-Learning.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99884607 0.99884607 0.99884607 0.99884607 0.99884607] [0. 0. 0. 0. 0.]\n",
      "[0.50542709 0.96814535 0.96814535 0.96814535 0.96838131] [0. 0. 0. 0. 0.]\n",
      "[0.42906919 0.44798407 0.95470383 0.95818815 0.95893479] [0. 0. 0. 0. 0.]\n",
      "[0.48301536 0.48627268 0.45416473 0.98557469 0.98557469] [0. 0. 0. 0. 0.]\n",
      "[0.5220034  0.53294432 0.68247022 0.67882324 0.94407975] [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "       print(mean_vals[:, j],std_vals[:, j]/np.sqrt(n_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "\n",
    "def simple_axis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 237.6x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fractional Correctness = Average of cross validation accuracies of learned tasks only after training each task \n",
    "fig = plt.figure(figsize=(3.3,2.5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_stuff = []\n",
    "    std_stuff = []\n",
    "    for i in range(len(data['mean'][cval])):\n",
    "        mean_stuff.append(data['mean'][cval][i][:i+1].mean())\n",
    "        std_stuff.append(np.sqrt((data['std'][cval][i][:i+1]**2).sum())/(n_stats*np.sqrt(n_stats)))\n",
    "    # plot(range(1,n_tasks+1), mean_stuff, 'o-', label=\"c=%g\"%cval)\n",
    "    errorbar(range(0,n_tasks), mean_stuff, yerr=std_stuff, fmt='o-', label=\"c=%g\"%cval)\n",
    "        \n",
    "axhline(data['mean'][cval][0][0], linestyle='--', color='k')\n",
    "xlabel('Number of tasks')\n",
    "ylabel('Fraction correct')\n",
    "legend(loc='best')\n",
    "xlim(0, n_tasks)\n",
    "ylim(0.5, 1.02)\n",
    "# grid('on')\n",
    "# sns.despine()\n",
    "simple_axis(ax)\n",
    "plt.savefig('MNIST-5Task-Progressive-Transfer-Learning-fraction-correct.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of data for task-0 of shape-(10447, 500) is: 384\n",
      "----------------------------------------------------------------------\n",
      "Rank of data for task-1 of shape-(9893, 500) is: 410\n",
      "----------------------------------------------------------------------\n",
      "Rank of data for task-2 of shape-(9119, 500) is: 500\n",
      "----------------------------------------------------------------------\n",
      "Rank of data for task-3 of shape-(9871, 500) is: 500\n",
      "----------------------------------------------------------------------\n",
      "Rank of data for task-4 of shape-(9670, 500) is: 500\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#After Reducng dataset\n",
    "for j in range(n_tasks):\n",
    "    print('Rank of data for task-{0} of shape-{1} is: {2}'.format(j,training_datasets[j][0].shape,matrix_rank(np.matrix(training_datasets[j][0], dtype='float'))))\n",
    "    print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
