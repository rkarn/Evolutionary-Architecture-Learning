{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training csv file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,74,88) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing csv file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/root/awid_dataset/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
    "\n",
    "# Read in the CSV files\n",
    "dataset_columns = ['frame.interface_id',\t'frame.dlt',\t'frame.offset_shift',\t'frame.time_epoch',\t'frame.time_delta',\t'frame.time_delta_displayed',\t'frame.time_relative',\t'frame.len',\t'frame.cap_len',\t'frame.marked',\t'frame.ignored',\t'radiotap.version',\t'radiotap.pad',\t'radiotap.length',\t'radiotap.present.tsft',\t'radiotap.present.flags',\t'radiotap.present.rate',\t'radiotap.present.channel',\t'radiotap.present.fhss',\t'radiotap.present.dbm_antsignal',\t'radiotap.present.dbm_antnoise',\t'radiotap.present.lock_quality',\t'radiotap.present.tx_attenuation',\t'radiotap.present.db_tx_attenuation',\t'radiotap.present.dbm_tx_power',\t'radiotap.present.antenna',\t'radiotap.present.db_antsignal',\t'radiotap.present.db_antnoise',\t'radiotap.present.rxflags',\t'radiotap.present.xchannel',\t'radiotap.present.mcs',\t'radiotap.present.ampdu',\t'radiotap.present.vht',\t'radiotap.present.reserved',\t'radiotap.present.rtap_ns',\t'radiotap.present.vendor_ns',\t'radiotap.present.ext',\t'radiotap.mactime',\t'radiotap.flags.cfp',\t'radiotap.flags.preamble',\t'radiotap.flags.wep',\t'radiotap.flags.frag',\t'radiotap.flags.fcs',\t'radiotap.flags.datapad',\t'radiotap.flags.badfcs',\t'radiotap.flags.shortgi',\t'radiotap.datarate',\t'radiotap.channel.freq',\t'radiotap.channel.type.turbo',\t'radiotap.channel.type.cck',\t'radiotap.channel.type.ofdm',\t'radiotap.channel.type.2ghz',\t'radiotap.channel.type.5ghz',\t'radiotap.channel.type.passive',\t'radiotap.channel.type.dynamic',\t'radiotap.channel.type.gfsk',\t'radiotap.channel.type.gsm',\t'radiotap.channel.type.sturbo',\t'radiotap.channel.type.half',\t'radiotap.channel.type.quarter',\t'radiotap.dbm_antsignal',\t'radiotap.antenna',\t'radiotap.rxflags.badplcp',\t'wlan.fc.type_subtype',\t'wlan.fc.version',\t'wlan.fc.type',\t'wlan.fc.subtype',\t'wlan.fc.ds',\t'wlan.fc.frag',\t'wlan.fc.retry',\t'wlan.fc.pwrmgt',\t'wlan.fc.moredata',\t'wlan.fc.protected',\t'wlan.fc.order',\t'wlan.duration',\t'wlan.ra',\t'wlan.da',\t'wlan.ta',\t'wlan.sa',\t'wlan.bssid',\t'wlan.frag',\t'wlan.seq',\t'wlan.bar.type',\t'wlan.ba.control.ackpolicy',\t'wlan.ba.control.multitid',\t'wlan.ba.control.cbitmap',\t'wlan.bar.compressed.tidinfo',\t'wlan.ba.bm',\t'wlan.fcs_good',\t'wlan_mgt.fixed.capabilities.ess',\t'wlan_mgt.fixed.capabilities.ibss',\t'wlan_mgt.fixed.capabilities.cfpoll.ap',\t'wlan_mgt.fixed.capabilities.privacy',\t'wlan_mgt.fixed.capabilities.preamble',\t'wlan_mgt.fixed.capabilities.pbcc',\t'wlan_mgt.fixed.capabilities.agility',\t'wlan_mgt.fixed.capabilities.spec_man',\t'wlan_mgt.fixed.capabilities.short_slot_time',\t'wlan_mgt.fixed.capabilities.apsd',\t'wlan_mgt.fixed.capabilities.radio_measurement',\t'wlan_mgt.fixed.capabilities.dsss_ofdm',\t'wlan_mgt.fixed.capabilities.del_blk_ack',\t'wlan_mgt.fixed.capabilities.imm_blk_ack',\t'wlan_mgt.fixed.listen_ival',\t'wlan_mgt.fixed.current_ap',\t'wlan_mgt.fixed.status_code',\t'wlan_mgt.fixed.timestamp',\t'wlan_mgt.fixed.beacon',\t'wlan_mgt.fixed.aid',\t'wlan_mgt.fixed.reason_code',\t'wlan_mgt.fixed.auth.alg',\t'wlan_mgt.fixed.auth_seq',\t'wlan_mgt.fixed.category_code',\t'wlan_mgt.fixed.htact',\t'wlan_mgt.fixed.chanwidth',\t'wlan_mgt.fixed.fragment',\t'wlan_mgt.fixed.sequence',\t'wlan_mgt.tagged.all',\t'wlan_mgt.ssid',\t'wlan_mgt.ds.current_channel',\t'wlan_mgt.tim.dtim_count',\t'wlan_mgt.tim.dtim_period',\t'wlan_mgt.tim.bmapctl.multicast',\t'wlan_mgt.tim.bmapctl.offset',\t'wlan_mgt.country_info.environment',\t'wlan_mgt.rsn.version',\t'wlan_mgt.rsn.gcs.type',\t'wlan_mgt.rsn.pcs.count',\t'wlan_mgt.rsn.akms.count',\t'wlan_mgt.rsn.akms.type',\t'wlan_mgt.rsn.capabilities.preauth',\t'wlan_mgt.rsn.capabilities.no_pairwise',\t'wlan_mgt.rsn.capabilities.ptksa_replay_counter',\t'wlan_mgt.rsn.capabilities.gtksa_replay_counter',\t'wlan_mgt.rsn.capabilities.mfpr',\t'wlan_mgt.rsn.capabilities.mfpc',\t'wlan_mgt.rsn.capabilities.peerkey',\t'wlan_mgt.tcprep.trsmt_pow',\t'wlan_mgt.tcprep.link_mrg',\t'wlan.wep.iv',\t'wlan.wep.key',\t'wlan.wep.icv',\t'wlan.tkip.extiv',\t'wlan.ccmp.extiv',\t'wlan.qos.tid',\t'wlan.qos.priority',\t'wlan.qos.eosp',\t'wlan.qos.ack',\t'wlan.qos.amsdupresent',\t'wlan.qos.buf_state_indicated',\t'wlan.qos.bit4',\t'wlan.qos.txop_dur_req',\t'wlan.qos.buf_state_indicated',\t'data.len',\t'class']\n",
    "\n",
    "print(\"Reading training csv file.\")\n",
    "df1 = pd.read_csv('awid_train_set')\n",
    "df1.columns = dataset_columns\n",
    "df1=df1.replace('?',0)\n",
    "\n",
    "df1.drop([dataset_columns[i] for i in [33, 63, 67, 75, 76, 77, 78, 79, 82, 86, 87, 91, 103, 104, 105, 106, 108, 109, 111, 113, 114,118, 123, 124, 132, 133, 139,  141, 142, 143, 147 ]], axis=1, inplace=True) \n",
    "\n",
    "print(\"Reading testing csv file.\")\n",
    "df2 = pd.read_csv('awid_test_set')\n",
    "df2.columns = dataset_columns\n",
    "df2=df2.replace('?',0)\n",
    "\n",
    "df2.drop([dataset_columns[i] for i in [33, 63, 67, 75, 76, 77, 78, 79, 82, 86, 87, 91, 103, 104, 105, 106, 108, 109, 111, 113, 114,118, 123, 124, 132, 133, 139,  141, 142, 143, 147 ]], axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probe_response', 'authentication_request'} {'rts', 'probe_request', 'disassociation', 'chop_chop', 'cts', 'hirte', 'power_saving'}\n"
     ]
    }
   ],
   "source": [
    "print(set(df2['class'].unique()) - set(df1['class'].unique()), set(df1['class'].unique()) - set(df2['class'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2371216 575642 1795574 2371216\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df1, df2])\n",
    "print(len(df),len(df1),len(df2),len(df1)+len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 ['normal' 'fragmentation' 'arp' 'probe_request' 'chop_chop' 'rts'\n",
      " 'deauthentication' 'amok' 'beacon' 'evil_twin' 'cafe_latte' 'cts' 'hirte'\n",
      " 'power_saving' 'disassociation' 'authentication_request' 'probe_response']\n",
      "/root/pathint/fig_split_mnist\n"
     ]
    }
   ],
   "source": [
    "#max([float(i) for i in df1[dataset_columns[37]]])\n",
    "#[dataset_columns[i] for i in [71, 72, 73, 74, 86, 98, 99, 100, 101, 103, 104]]\n",
    "#dataset_columns.index(df1.columns[79])\n",
    "print (len(df['class'].unique()),df['class'].unique())\n",
    "os.chdir('/root/pathint/fig_split_mnist/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2371216, 123)\n",
      "Datasetset Formatting\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "obj_df = df; \n",
    "Y_all_attacks = obj_df[\"class\"]\n",
    "#obj_df=pd.get_dummies(obj_df, columns=[\"class\"])\n",
    "\n",
    "\n",
    "X = obj_df.values[:,:-1]  #It has 17 labels \n",
    "print (X.shape)\n",
    "print(\"Datasetset Formatting\")\n",
    "for j in range(0,123):\n",
    "    maximum = max([float(k) for k in X[:,j]]) if  max([float(k) for k in X[:,j]]) != 0 else 1\n",
    "    print(j)\n",
    "    for i in range(0,len(X)):\n",
    "        X[i,j] = round(float(X[i,j])/maximum,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2371216, 123)\n",
      "(1588714, 123)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train_all_attacks, Y_test_all_attacks = train_test_split(X, Y_all_attacks, test_size=0.33)\n",
    "print (X_train.shape)\n",
    "\n",
    "#['normal' 'fragmentation' 'arp' 'probe_request' 'chop_chop' 'rts' 'deauthentication' 'amok' 'beacon' 'evil_twin' 'cafe_latte' 'cts' 'hirte' 'power_saving' 'disassociation' 'authentication_request' 'probe_response']\n",
    "cleanup_nums = {\"normal\":0, \"fragmentation\":1, \"arp\":2, \"probe_request\":3, \"chop_chop\":4, \"rts\":5, \"deauthentication\":6, \"amok\":7, \"beacon\":8, \"evil_twin\":9, \"cafe_latte\":10, \"cts\":11, \"hirte\":12, \"power_saving\":13, \"disassociation\":14, \"authentication_request\":15, \"probe_response\":16}\n",
    "Y_train_all_attacks.replace(cleanup_nums,inplace=True)\n",
    "Y_test_all_attacks.replace(cleanup_nums,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1588714, 123), (782502, 123), (2371216, 124), (2371216, 123))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(df2.columns),len(df1.columns),len(df.columns)\n",
    "X_train.shape, X_test.shape, obj_df.values.shape, obj_df.values[:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1588714, 100), (782502, 100))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataset with only 100 features out of 123\n",
    "feature_set = 100\n",
    "X_train_reduced = X_train[:,:feature_set]\n",
    "X_test_reduced = X_test[:,:feature_set]\n",
    "X_train_reduced.shape, X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['select', 'average']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "input_dim = 100\n",
    "output_dim = 17\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 123\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 64\n",
    "epochs_per_task = 10\n",
    "\n",
    "n_stats = 1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "#task_labels = [[8,1],[5,3],[4,9], [11,7], [6,2], [0,10], [14,2],[12,13]]\n",
    "task_labels = [[0,1],[2,3],[4,5],[6,7],[8,9],[10,11],[12,13],[14,15],[16,0]]\n",
    "#task_labels = [[0,9], [7,8], [3,6], [1,4], [2,5]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8],[9,10,11],[12,13,14],[15,16]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "n_tasks = len(task_labels)\n",
    "nb_classes  = 17\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_train_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_train_reduced[idx], np_utils.to_categorical(label_map[Y_train_all_attacks[idx]], len(labels))\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_train[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(label_map[Y_train_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_train_reduced[idx], np_utils.to_categorical(Y_train_all_attacks[idx], nb_classes)\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_train[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(Y_train_all_attacks[idx], nb_classes)\n",
    "        training_datasets.append(data)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_test_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_test_reduced[idx], np_utils.to_categorical(label_map[Y_test_all_attacks[idx]], len(labels))\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_test[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(label_map[Y_test_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_test_reduced[idx], np_utils.to_categorical(Y_test_all_attacks[idx], nb_classes)\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_test[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(Y_test_all_attacks[idx], nb_classes)\n",
    "        validation_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import keras.backend as K\n",
    "import keras.activations as activations\n",
    "\n",
    "output_mask = tf.Variable(tf.zeros(output_dim), name=\"mask\", trainable=False)\n",
    "\n",
    "def masked_softmax(logits):\n",
    "    # logits are [batch_size, output_dim]\n",
    "    x = select(tf.tile(tf.equal(output_mask[None, :], 1.0), [tf.shape(logits)[0], 1]), logits, -1e32 * tf.ones_like(logits))\n",
    "    return activations.softmax(x)\n",
    "\n",
    "def set_active_outputs(labels):\n",
    "    new_mask = np.zeros(output_dim)\n",
    "    for l in labels:\n",
    "        new_mask[l] = 1.0\n",
    "    sess.run(output_mask.assign(new_mask))\n",
    "    print(sess.run(output_mask))\n",
    "    \n",
    "def masked_predict(model, data, targets):\n",
    "    pred = model.predict(data)\n",
    "    print(pred)\n",
    "    acc = np.argmax(pred,1)==np.argmax(targets,1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(123, kernel_initializer='random_uniform', activation=activation_fn, input_shape=(input_dim,)))\n",
    "#model.add(Dense(30, kernel_initializer='random_uniform', activation=activation_fn))\n",
    "#model.add(Dense(n_hidden_units, activation=activation_fn))\n",
    "model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax))\n",
    "\n",
    "from pathint import protocols\n",
    "from pathint.optimizers import KOOptimizer\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.callbacks import Callback\n",
    "from pathint.keras_utils import LossHistory\n",
    "\n",
    "#protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "#protocol_name, protocol = protocols.FISHER_PROTOCOL('sum')\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#opt = SGD(1e-3)\n",
    "#opt = RMSprop(lr=1e-3)\n",
    "oopt = KOOptimizer(opt, model=model, **protocol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=oopt, metrics=['accuracy'])\n",
    "model.model._make_train_function()\n",
    "saved_weights = model.get_weights()\n",
    "\n",
    "history = LossHistory()\n",
    "callbacks = [history]\n",
    "datafile_name = \"split_mnist_data_%s.pkl.gz\"%protocol_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_updates': [('omega', <function <lambda>.<locals>.<lambda> at 0x7f2699657d08>), ('cweights', <function <lambda>.<locals>.<lambda> at 0x7f2699b03620>), ('grads2', <function <lambda>.<locals>.<lambda> at 0x7f2699662840>)], 'init_updates': [('cweights', <function <lambda>.<locals>.<lambda> at 0x7f2699657d90>)], 'step_updates': [('grads2', <function <lambda>.<locals>.<lambda> at 0x7f2699657510>)], 'regularizer_fn': <function quadratic_regularizer at 0x7f26d0df4510>}\n"
     ]
    }
   ],
   "source": [
    "print(protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_fits(cvals, training_data, valid_data, eval_on_train_set=False, nstats=1):\n",
    "    acc_mean = dict()\n",
    "    acc_std = dict()\n",
    "    model_weights_save = []   #Empty list to save the model weights aftertraining each task\n",
    "    for cidx, cval_ in enumerate(tqdm(cvals)):\n",
    "        runs = []\n",
    "        for runid in range(nstats):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # model.set_weights(saved_weights)\n",
    "            cstuffs = []\n",
    "            evals = []\n",
    "            print(\"setting cval\")\n",
    "            cval = cval_\n",
    "            oopt.set_strength(cval)\n",
    "            oopt.init_task_vars()\n",
    "            print(\"cval is\", sess.run(oopt.lam))\n",
    "            for age, tidx in enumerate(range(n_tasks)):\n",
    "                print(\"Age %i, cval is=%f\"%(age,cval))\n",
    "                print(\"settint output mask\")\n",
    "                set_active_outputs(task_labels[age])\n",
    "                stuffs = model.fit(training_data[tidx][0], training_data[tidx][1], batch_size, epochs_per_task, callbacks=callbacks)\n",
    "                oopt.update_task_metrics(training_data[tidx][0], training_data[tidx][1], batch_size)\n",
    "                oopt.update_task_vars()\n",
    "                ftask = []\n",
    "                model_weights_save.append(model.get_weights()) #Save the model weights aftertraining each task\n",
    "                for j in range(n_tasks):\n",
    "                    set_active_outputs(task_labels[j])\n",
    "                    if eval_on_train_set:\n",
    "                        f_ = masked_predict(model, training_data[j][0], training_data[j][1])\n",
    "                    else:\n",
    "                        f_ = masked_predict(model, valid_data[j][0], valid_data[j][1])\n",
    "                    ftask.append(np.mean(f_))\n",
    "                evals.append(ftask)\n",
    "                cstuffs.append(stuffs)\n",
    "\n",
    "                # Re-initialize optimizater variables\n",
    "                if reset_optimizer:\n",
    "                    oopt.reset_optimizer()\n",
    "\n",
    "            evals = np.array(evals)\n",
    "            runs.append(evals)\n",
    "        \n",
    "        runs = np.array(runs)\n",
    "        acc_mean[cval_] = runs.mean(0)\n",
    "        acc_std[cval_] = runs.std(0)\n",
    "    return dict(mean=acc_mean, std=acc_std),model_weights_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "# cvals = np.concatenate(([0], np.logspace(-2, 2, 10)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-1, 2, 2)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-2, 0, 3)))\n",
    "#cvals = np.logspace(-3, 3, 7)#[0, 1.0, 2, 5, 10]\n",
    "cvals = [1.0]\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 1.0\n",
      "Age 0, cval is=1.000000\n",
      "settint output mask\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "1450112/1450112 [==============================] - 75s - loss: 8.7471e-04 - acc: 0.9998    \n",
      "Epoch 2/10\n",
      "1450112/1450112 [==============================] - 74s - loss: 1.9675e-04 - acc: 0.9999    \n",
      "Epoch 3/10\n",
      "1450112/1450112 [==============================] - 74s - loss: 1.1976e-04 - acc: 1.0000    \n",
      "Epoch 4/10\n",
      "1450112/1450112 [==============================] - 74s - loss: 1.2477e-04 - acc: 1.0000    \n",
      "Epoch 5/10\n",
      "1450112/1450112 [==============================] - 75s - loss: 1.0432e-04 - acc: 1.0000    \n",
      "Epoch 6/10\n",
      "1450112/1450112 [==============================] - 74s - loss: 8.7224e-05 - acc: 1.0000    \n",
      "Epoch 7/10\n",
      "1450112/1450112 [==============================] - 75s - loss: 8.1931e-05 - acc: 1.0000    \n",
      "Epoch 8/10\n",
      "1450112/1450112 [==============================] - 75s - loss: 8.3724e-05 - acc: 1.0000    \n",
      "Epoch 9/10\n",
      "1450112/1450112 [==============================] - 75s - loss: 7.5886e-05 - acc: 1.0000    \n",
      "Epoch 10/10\n",
      "1450112/1450112 [==============================] - 75s - loss: 8.5752e-05 - acc: 1.0000    \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 7.4575674e-27 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.0442407e-21 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [1.0000000e+00 1.8959569e-32 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 2.7932702e-32 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.48465067 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.48849413 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.49366206 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.50234735 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.48492628 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.49393243 ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.         0.         0.         ... 0.49928576 0.50071424 0.        ]\n",
      " [0.         0.         0.         ... 0.5104712  0.48952875 0.        ]\n",
      " [0.         0.         0.         ... 0.5101092  0.48989075 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5046792  0.4953208  0.        ]\n",
      " [0.         0.         0.         ... 0.50756645 0.4924335  0.        ]\n",
      " [0.         0.         0.         ... 0.4974023  0.50259763 0.        ]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[[9.9919754e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 8.0251601e-04]\n",
      " [9.8462242e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.5377531e-02]\n",
      " [9.8815364e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.1846325e-02]\n",
      " ...\n",
      " [9.9263048e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.3694903e-03]\n",
      " [9.9013406e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 9.8659750e-03]\n",
      " [4.6369353e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.3630644e-01]]\n",
      "Age 1, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "52939/52939 [==============================] - 2s - loss: 0.0128 - acc: 0.9956     \n",
      "Epoch 2/10\n",
      "52939/52939 [==============================] - 2s - loss: 0.0019 - acc: 0.9998     \n",
      "Epoch 3/10\n",
      "52939/52939 [==============================] - 2s - loss: 7.2851e-04 - acc: 0.9999     \n",
      "Epoch 4/10\n",
      "52939/52939 [==============================] - 2s - loss: 4.2236e-04 - acc: 1.0000     \n",
      "Epoch 5/10\n",
      "52939/52939 [==============================] - 2s - loss: 2.4888e-04 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "52939/52939 [==============================] - 2s - loss: 1.5263e-04 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "52939/52939 [==============================] - 2s - loss: 1.0778e-04 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "52939/52939 [==============================] - 2s - loss: 7.1062e-05 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "52939/52939 [==============================] - 2s - loss: 6.1312e-05 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "52939/52939 [==============================] - 2s - loss: 5.1095e-05 - acc: 1.0000     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 9.6910946e-27 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.7190068e-21 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [1.0000000e+00 1.0825336e-29 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 3.7933843e-32 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.99999964 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999994  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999999  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.99993706 ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999938  ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.         0.         0.         ... 0.49928612 0.5007139  0.        ]\n",
      " [0.         0.         0.         ... 0.5104721  0.48952785 0.        ]\n",
      " [0.         0.         0.         ... 0.51010996 0.48989    0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5046801  0.4953199  0.        ]\n",
      " [0.         0.         0.         ... 0.50756735 0.49243262 0.        ]\n",
      " [0.         0.         0.         ... 0.49740258 0.50259745 0.        ]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9919719e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 8.0280623e-04]\n",
      " [9.8458362e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.5416451e-02]\n",
      " [9.8814410e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.1855948e-02]\n",
      " ...\n",
      " [9.9259233e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.4076899e-03]\n",
      " [9.9013817e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 9.8618530e-03]\n",
      " [4.6372667e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.3627336e-01]]\n",
      "Age 2, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.2738 - acc: 0.9147     \n",
      "Epoch 2/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.0339 - acc: 0.9995     \n",
      "Epoch 3/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.0079 - acc: 1.0000     \n",
      "Epoch 4/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.0040 - acc: 1.0000     \n",
      "Epoch 5/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.0027 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.0020 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.0016 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.0013 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "2005/2005 [==============================] - 0s - loss: 0.0011 - acc: 1.0000        \n",
      "Epoch 10/10\n",
      "2005/2005 [==============================] - 0s - loss: 9.4120e-04 - acc: 1.0000     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 9.68311277e-27 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.71655922e-21 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00 1.08130374e-29 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.78988401e-32 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.99999964 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999994  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999999  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.99993706 ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999938  ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.         0.         0.         ... 0.50116444 0.49883553 0.        ]\n",
      " [0.         0.         0.         ... 0.5960788  0.4039211  0.        ]\n",
      " [0.         0.         0.         ... 0.5273925  0.47260746 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5562166  0.44378337 0.        ]\n",
      " [0.         0.         0.         ... 0.57648844 0.4235116  0.        ]\n",
      " [0.         0.         0.         ... 0.4850448  0.5149552  0.        ]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[[9.9998820e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.1826290e-05]\n",
      " [9.9929869e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.0130202e-04]\n",
      " [9.9420726e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.7927119e-03]\n",
      " ...\n",
      " [9.9907279e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 9.2720654e-04]\n",
      " [9.9818951e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.8105411e-03]\n",
      " [7.8542197e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.1457811e-01]]\n",
      "Age 3, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.2165 - acc: 0.9157     \n",
      "Epoch 2/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0968 - acc: 0.9683     \n",
      "Epoch 3/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0688 - acc: 0.9772     \n",
      "Epoch 4/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0562 - acc: 0.9842     \n",
      "Epoch 5/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0479 - acc: 0.9879     \n",
      "Epoch 6/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0422 - acc: 0.9902     \n",
      "Epoch 7/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0379 - acc: 0.9912     \n",
      "Epoch 8/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0349 - acc: 0.9921     \n",
      "Epoch 9/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0316 - acc: 0.9933     \n",
      "Epoch 10/10\n",
      "31356/31356 [==============================] - 1s - loss: 0.0296 - acc: 0.9936     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 9.63109648e-27 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.70667384e-21 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00 1.07629955e-29 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.76222727e-32 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.99999964 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999994  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999999  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.9999385  ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999938  ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.         0.         0.         ... 0.49364582 0.50635415 0.        ]\n",
      " [0.         0.         0.         ... 0.5879994  0.41200057 0.        ]\n",
      " [0.         0.         0.         ... 0.53968596 0.46031404 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5485774  0.45142257 0.        ]\n",
      " [0.         0.         0.         ... 0.56822145 0.43177858 0.        ]\n",
      " [0.         0.         0.         ... 0.47747874 0.5225213  0.        ]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9999142e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 8.5442271e-06]\n",
      " [9.9864918e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.3507946e-03]\n",
      " [9.9328387e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 6.7160921e-03]\n",
      " ...\n",
      " [9.9865353e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.3463980e-03]\n",
      " [9.9941504e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.8496371e-04]\n",
      " [8.0562538e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.9437462e-01]]\n",
      "Age 4, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.2129 - acc: 0.9481     \n",
      "Epoch 2/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0304 - acc: 0.9989     \n",
      "Epoch 3/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0170 - acc: 0.9995     \n",
      "Epoch 4/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0124 - acc: 0.9995     \n",
      "Epoch 5/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0099 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0080 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0069 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0059 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0055 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "3776/3776 [==============================] - 0s - loss: 0.0048 - acc: 1.0000     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 1.00767598e-26 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.88914714e-21 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00 1.09710065e-29 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 3.88396381e-32 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.99999964 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999994  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999999  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.9999387  ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999939  ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.         0.         0.         ... 0.49293578 0.5070642  0.        ]\n",
      " [0.         0.         0.         ... 0.58744997 0.41255    0.        ]\n",
      " [0.         0.         0.         ... 0.5383756  0.46162435 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5480171  0.45198298 0.        ]\n",
      " [0.         0.         0.         ... 0.56768084 0.4323192  0.        ]\n",
      " [0.         0.         0.         ... 0.47721693 0.5227831  0.        ]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[[9.9999475e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.2650071e-06]\n",
      " [9.9862683e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.3731655e-03]\n",
      " [9.9247980e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.5202379e-03]\n",
      " ...\n",
      " [9.9808323e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.9168103e-03]\n",
      " [9.9955469e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 4.4525275e-04]\n",
      " [7.9461479e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.0538519e-01]]\n",
      "Age 5, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "32154/32154 [==============================] - 1s - loss: 0.0257 - acc: 0.9956     \n",
      "Epoch 2/10\n",
      "32154/32154 [==============================] - 1s - loss: 0.0037 - acc: 0.9999     \n",
      "Epoch 3/10\n",
      "32154/32154 [==============================] - 1s - loss: 0.0022 - acc: 0.9999     \n",
      "Epoch 4/10\n",
      "32154/32154 [==============================] - 1s - loss: 0.0015 - acc: 0.9999     \n",
      "Epoch 5/10\n",
      "32154/32154 [==============================] - 1s - loss: 0.0011 - acc: 0.9999     \n",
      "Epoch 6/10\n",
      "32154/32154 [==============================] - 1s - loss: 8.2326e-04 - acc: 0.9999     \n",
      "Epoch 7/10\n",
      "32154/32154 [==============================] - 1s - loss: 6.4472e-04 - acc: 0.9999     \n",
      "Epoch 8/10\n",
      "32154/32154 [==============================] - 1s - loss: 5.0528e-04 - acc: 0.9999     \n",
      "Epoch 9/10\n",
      "32154/32154 [==============================] - 1s - loss: 3.9026e-04 - acc: 0.9999     \n",
      "Epoch 10/10\n",
      "32154/32154 [==============================] - 1s - loss: 3.2951e-04 - acc: 0.9999     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.2909826e-26 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.4076028e-21 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [1.0000000e+00 1.2073127e-29 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.2308252e-32 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.99999964 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999994  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999999  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.9999392  ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999939  ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.         0.         0.         ... 0.4929671  0.5070329  0.        ]\n",
      " [0.         0.         0.         ... 0.5874638  0.41253614 0.        ]\n",
      " [0.         0.         0.         ... 0.5385731  0.4614269  0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.54802537 0.45197463 0.        ]\n",
      " [0.         0.         0.         ... 0.56769204 0.43230796 0.        ]\n",
      " [0.         0.         0.         ... 0.47721836 0.52278167 0.        ]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9999475e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.2418263e-06]\n",
      " [9.9863017e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.3699124e-03]\n",
      " [9.9247509e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.5248508e-03]\n",
      " ...\n",
      " [9.9776542e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.2346198e-03]\n",
      " [9.9955684e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 4.4316522e-04]\n",
      " [7.9367173e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.0632823e-01]]\n",
      "Age 6, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0523 - acc: 0.9955     \n",
      "Epoch 2/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0097 - acc: 0.9991     \n",
      "Epoch 3/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0058 - acc: 0.9995     \n",
      "Epoch 4/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0039 - acc: 0.9996     \n",
      "Epoch 5/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0029 - acc: 0.9998     \n",
      "Epoch 6/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0023 - acc: 0.9998     \n",
      "Epoch 7/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0019 - acc: 0.9998     \n",
      "Epoch 8/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0016 - acc: 0.9998     \n",
      "Epoch 9/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0014 - acc: 0.9998     \n",
      "Epoch 10/10\n",
      "12907/12907 [==============================] - 0s - loss: 0.0012 - acc: 0.9998      \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 1.24568155e-26 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 5.17286039e-21 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00 1.19016490e-29 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.08389042e-32 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.99999964 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999994  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999999  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.9999397  ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999939  ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.         0.         0.         ... 0.49294296 0.507057   0.        ]\n",
      " [0.         0.         0.         ... 0.58756375 0.4124362  0.        ]\n",
      " [0.         0.         0.         ... 0.53866625 0.46133375 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.5480622  0.45193782 0.        ]\n",
      " [0.         0.         0.         ... 0.56774646 0.4322536  0.        ]\n",
      " [0.         0.         0.         ... 0.477202   0.52279794 0.        ]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[[9.9999475e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.2218684e-06]\n",
      " [9.9863523e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.3647015e-03]\n",
      " [9.9262130e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.3786457e-03]\n",
      " ...\n",
      " [9.9774301e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.2570526e-03]\n",
      " [9.9956006e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 4.3987035e-04]\n",
      " [7.9675525e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.0324479e-01]]\n",
      "Age 7, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "Epoch 1/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.1409 - acc: 0.9605     \n",
      "Epoch 2/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0411 - acc: 0.9842     \n",
      "Epoch 3/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0324 - acc: 0.9904     \n",
      "Epoch 4/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0270 - acc: 0.9921     \n",
      "Epoch 5/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0230 - acc: 0.9925     \n",
      "Epoch 6/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0201 - acc: 0.9942     \n",
      "Epoch 7/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0178 - acc: 0.9950     \n",
      "Epoch 8/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0159 - acc: 0.9975     \n",
      "Epoch 9/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0144 - acc: 0.9996     \n",
      "Epoch 10/10\n",
      "2403/2403 [==============================] - 0s - loss: 0.0130 - acc: 0.9992     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.2446888e-26 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 5.1684022e-21 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [1.0000000e+00 1.1885134e-29 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 4.0800909e-32 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.99999964 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999994  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999999  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.9999397  ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999939  ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 8.3396817e-03\n",
      "  9.9166030e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.2198356e-04\n",
      "  9.9987805e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.0803213e-02\n",
      "  9.0919679e-01 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 7.6336949e-04\n",
      "  9.9923670e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.2152605e-04\n",
      "  9.9967849e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0269373e-03\n",
      "  9.9897313e-01 0.0000000e+00]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9999475e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 5.1997044e-06]\n",
      " [9.9863094e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.3690169e-03]\n",
      " [9.9259865e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.4014100e-03]\n",
      " ...\n",
      " [9.9774534e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.2545839e-03]\n",
      " [9.9956208e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 4.3792723e-04]\n",
      " [7.9642868e-01 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.0357130e-01]]\n",
      "Age 8, cval is=1.000000\n",
      "settint output mask\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Epoch 1/10\n",
      "1450571/1450571 [==============================] - 54s - loss: 6.3666e-04 - acc: 0.9999    \n",
      "Epoch 2/10\n",
      "1450571/1450571 [==============================] - 54s - loss: 2.3399e-05 - acc: 1.0000    \n",
      "Epoch 3/10\n",
      "1450571/1450571 [==============================] - 54s - loss: 2.3332e-05 - acc: 1.0000    \n",
      "Epoch 4/10\n",
      "1450571/1450571 [==============================] - 55s - loss: 2.2545e-05 - acc: 1.0000    \n",
      "Epoch 5/10\n",
      "1450571/1450571 [==============================] - 55s - loss: 2.2659e-05 - acc: 1.0000    \n",
      "Epoch 6/10\n",
      "1450571/1450571 [==============================] - 55s - loss: 2.2465e-05 - acc: 1.0000    \n",
      "Epoch 7/10\n",
      "1450571/1450571 [==============================] - 55s - loss: 2.2460e-05 - acc: 1.0000    \n",
      "Epoch 8/10\n",
      "1450571/1450571 [==============================] - 55s - loss: 2.2369e-05 - acc: 1.0000    \n",
      "Epoch 9/10\n",
      "1450571/1450571 [==============================] - 55s - loss: 2.2346e-05 - acc: 1.0000    \n",
      "Epoch 10/10\n",
      "1450571/1450571 [==============================] - 55s - loss: 2.2344e-05 - acc: 1.0000    \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.6908307e-28 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 6.2974261e-23 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [1.0000000e+00 1.6246540e-29 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.4268744e-33 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0.         0.         0.99999964 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999994  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.9999999  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.9999392  ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.99999404 ... 0.         0.         0.        ]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 8.3396342e-03\n",
      "  9.9166042e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.2197077e-04\n",
      "  9.9987805e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 9.0803936e-02\n",
      "  9.0919602e-01 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 7.6333451e-04\n",
      "  9.9923670e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.2149814e-04\n",
      "  9.9967849e-01 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0269159e-03\n",
      "  9.9897313e-01 0.0000000e+00]]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|| 1/1 [28:17<00:00, 1697.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 4.2856716e-21]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.8541436e-18]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.0640931e-14]\n",
      " ...\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 9.6061800e-35]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.6563924e-16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "recompute_data = True\n",
    "\n",
    "if recompute_data:\n",
    "    data,model_weights_save = run_fits(cvals, training_datasets, validation_datasets, eval_on_train_set=False, nstats=n_stats)\n",
    "    utils.save_zipped_pickle(data, datafile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 123)               12423     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                2108      \n",
      "=================================================================\n",
      "Total params: 14,531\n",
      "Trainable params: 14,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(100, 123)\n",
      "(123,)\n",
      "(123, 17)\n",
      "(17,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(model.summary())\n",
    "model.save_weights('saved_weights.h5') #This file cannot be opend normaly to view the weghts. It can be loaded through load_model() or can be opend via hdf5 viewer\n",
    "\n",
    "#Shape of the array containg model weights\n",
    "a_list = model.get_weights()\n",
    "for i in range(len(a_list)):\n",
    "    print((np.array(a_list[i])).shape)\n",
    "\n",
    "#a_list[0][0][0] = a_list[0][0][0]+0.00001\n",
    "#print(a_list[0][0][0])\n",
    "#model.set_weights(a_list)\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_zipped_pickle(datafile_name)\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': {1.0: array([[0.99998601, 0.10617918, 0.30328638, 0.31929178, 0.42015005,\n",
      "        0.24318024, 0.99023161, 0.52751905, 0.82516365],\n",
      "       [0.99998601, 1.        , 0.30328638, 0.31929178, 0.42015005,\n",
      "        0.24318024, 0.99023161, 0.52751905, 0.82517204],\n",
      "       [0.99998601, 1.        , 1.        , 0.3063911 , 0.2920686 ,\n",
      "        0.68638569, 0.99023161, 0.43607113, 0.97387127],\n",
      "       [0.99998601, 1.        , 1.        , 0.9940104 , 0.04394427,\n",
      "        0.67983368, 0.99023161, 0.52413209, 0.97397197],\n",
      "       [0.99998601, 1.        , 1.        , 0.99348384, 0.99732047,\n",
      "        0.68594469, 0.9899165 , 0.52328535, 0.9723565 ],\n",
      "       [0.99998601, 1.        , 1.        , 0.99348384, 0.99732047,\n",
      "        0.999811  , 0.9899165 , 0.52328535, 0.97250615],\n",
      "       [0.99998601, 1.        , 1.        , 0.99354966, 0.99732047,\n",
      "        0.999811  , 0.9968489 , 0.52328535, 0.97259147],\n",
      "       [0.99998601, 1.        , 1.        , 0.99348384, 0.99732047,\n",
      "        0.999811  , 0.9968489 , 0.9872989 , 0.97261106],\n",
      "       [0.99998461, 1.        , 1.        , 0.99348384, 0.99732047,\n",
      "        0.999811  , 0.9968489 , 0.9872989 , 0.99998461]])}, 'std': {1.0: array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]])}}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.colors as colors\n",
    "cmap = plt.get_cmap('cool') \n",
    "cNorm  = colors.Normalize(vmin=-5, vmax=np.log(np.max(list(data['mean'].keys()))))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "print(scalarMap.get_clim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x180 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(14, 2.5))\n",
    "axs = [subplot(1,n_tasks+1,1)]#, None, None]\n",
    "for i in range(1, n_tasks + 1):\n",
    "    axs.append(subplot(1, n_tasks+1, i+1, sharex=axs[0], sharey=axs[0]))\n",
    "    \n",
    "keys = list(data['mean'].keys())\n",
    "sorted_keys = np.sort(keys)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "        colorVal = scalarMap.to_rgba(np.log(cval))\n",
    "        # axs[j].plot(evals[:, j], c=colorVal)\n",
    "        axs[j].errorbar(range(n_tasks), mean_vals[:, j], yerr=std_vals[:, j]/np.sqrt(n_stats), c=colorVal)\n",
    "    label = \"c=%g\"%cval\n",
    "    average = mean_vals.mean(1)  #Taking the average of cross validation accuracies accross all tasks after learning each task\n",
    "    axs[-1].plot(average, c=colorVal, label=label)\n",
    "    \n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title((['task %d'%j for j in range(n_tasks)] + ['average'])[i])\n",
    "gcf().tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig('2Attack_Accuracy_AWID_Saturation_Detection.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "\n",
    "def simple_axis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 237.6x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fractional Correctness = Average of cross validation accuracies of learned tasks only after training each task \n",
    "fig = plt.figure(figsize=(3.3,2.5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_stuff = []\n",
    "    std_stuff = []\n",
    "    for i in range(len(data['mean'][cval])):\n",
    "        mean_stuff.append(data['mean'][cval][i][:i+1].mean())\n",
    "        std_stuff.append(np.sqrt((data['std'][cval][i][:i+1]**2).sum())/(n_stats*np.sqrt(n_stats)))\n",
    "    # plot(range(1,n_tasks+1), mean_stuff, 'o-', label=\"c=%g\"%cval)\n",
    "    errorbar(range(1,n_tasks+1), mean_stuff, yerr=std_stuff, fmt='o-', label=\"c=%g\"%cval)\n",
    "        \n",
    "axhline(data['mean'][cval][0][0], linestyle='--', color='k')\n",
    "xlabel('Number of tasks')\n",
    "ylabel('Fraction correct')\n",
    "legend(loc='best')\n",
    "xlim(0.5, 8.5)\n",
    "ylim(0.5, 1.02)\n",
    "# grid('on')\n",
    "# sns.despine()\n",
    "simple_axis(ax)\n",
    "plt.savefig('2attack_fractional_correct_AWID.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
