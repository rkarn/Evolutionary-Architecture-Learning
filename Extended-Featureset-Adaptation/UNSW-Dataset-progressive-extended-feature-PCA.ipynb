{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training csv file.\n",
      "Reading Testing csv file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('/Users/rupesh.karn/Desktop/WorkPart-1/UNSW-NB15 Dataset')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
    "\n",
    "# Read in the training CSV file\n",
    "print(\"Reading Training csv file.\")\n",
    "df1 = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "df1.drop('label', axis=1, inplace=True)\n",
    "\n",
    "obj_df=df1\n",
    "\n",
    "obj_df[\"proto\"] = obj_df[\"proto\"].astype('category')\n",
    "obj_df[\"service\"] = obj_df[\"service\"].astype('category')\n",
    "obj_df[\"state\"] = obj_df[\"state\"].astype('category')\n",
    "obj_df[\"proto_cat\"] = obj_df[\"proto\"].cat.codes\n",
    "obj_df[\"service_cat\"] = obj_df[\"service\"].cat.codes\n",
    "obj_df[\"state_cat\"] = obj_df[\"state\"].cat.codes\n",
    "\n",
    "obj_df[\"proto\"] = obj_df[\"proto_cat\"]\n",
    "obj_df[\"service\"] = obj_df[\"service_cat\"]\n",
    "obj_df[\"state\"] = obj_df[\"state_cat\"]\n",
    "\n",
    "obj_df.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "Y_train_all_attacks = obj_df[\"attack_cat\"]\n",
    "obj_df=pd.get_dummies(obj_df, columns=[\"attack_cat\"])\n",
    "\n",
    "\n",
    "X_train = obj_df.values[:,:-10]\n",
    "\n",
    "\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_train)):\n",
    "        X_train[i,j] = round(X_train[i,j]/maximum,3)\n",
    "\n",
    "# Read in the testing CSV file \n",
    "print(\"Reading Testing csv file.\")\n",
    "df2 = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
    "df2.drop('label', axis=1, inplace=True)\n",
    "\n",
    "obj_df2=df2\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto\"].astype('category')\n",
    "obj_df2[\"service\"] = obj_df2[\"service\"].astype('category')\n",
    "obj_df2[\"state\"] = obj_df2[\"state\"].astype('category')\n",
    "obj_df2[\"proto_cat\"] = obj_df2[\"proto\"].cat.codes\n",
    "obj_df2[\"service_cat\"] = obj_df2[\"service\"].cat.codes\n",
    "obj_df2[\"state_cat\"] = obj_df2[\"state\"].cat.codes\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto_cat\"]\n",
    "obj_df2[\"service\"] = obj_df2[\"service_cat\"]\n",
    "obj_df2[\"state\"] = obj_df2[\"state_cat\"]\n",
    "\n",
    "obj_df2.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "Y_test_all_attacks = obj_df2[\"attack_cat\"]\n",
    "obj_df2=pd.get_dummies(obj_df2, columns=[\"attack_cat\"])\n",
    "\n",
    "\n",
    "X_test = obj_df2.values[:,:-10]\n",
    "\n",
    "\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_test)):\n",
    "        X_test[i,j] = round(X_test[i,j]/maximum,3)\n",
    "\n",
    "\n",
    "estimators_number = list(range(10,30))\n",
    "\n",
    "dataspace = 0;\n",
    "overall_accuracy_matrix = [None]*len(X_train)\n",
    "iTERATION=0\n",
    "dataspace_number=1\n",
    "attack_type = 4\n",
    "Y_train = obj_df.values[:,-attack_type]\n",
    "Y_test = obj_df2.values[:,-attack_type]\n",
    "\n",
    "cleanup_nums = {\"Worms\":0, \"Shellcode\":1, \"Reconnaissance\":2, \"Normal\":3, \"Generic\":4, \"Fuzzers\":5, \"Exploits\":6, \"DoS\":7, \"Backdoor\":8, \"Analysis\":9}\n",
    "Y_train_all_attacks.replace(cleanup_nums,inplace=True)\n",
    "Y_test_all_attacks.replace(cleanup_nums,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82332, 35), (175341, 35))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataset with only 35 features out of 43\n",
    "feature_set = 35\n",
    "X_train_reduced = X_train[:,:feature_set]\n",
    "X_test_reduced = X_test[:,:feature_set]\n",
    "X_train_reduced.shape, X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['maximum', 'pylab', 'draw_if_interactive']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "input_dim = 35\n",
    "output_dim = 10\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 35\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 64\n",
    "epochs_per_task = 10\n",
    "\n",
    "n_stats = 1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=35)\n",
    "\n",
    "#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[7,9],[3,8],[0,6],[4,2]]\n",
    "#task_labels = [[8,9], [6,7], [4,5], [2,3], [0,1]]\n",
    "#task_labels = [[0,9], [7,8], [3,6], [1,4], [2,5]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8,9]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9]]\n",
    "n_tasks = len(task_labels)\n",
    "nb_classes  = 10\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_train_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_train_reduced[idx], np_utils.to_categorical(label_map[Y_train_all_attacks[idx]], len(labels))\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_train[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(label_map[Y_train_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_train_reduced[idx], np_utils.to_categorical(Y_train_all_attacks[idx], nb_classes)\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_train[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(Y_train_all_attacks[idx], nb_classes)\n",
    "        training_datasets.append(data)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_test_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_test_reduced[idx], np_utils.to_categorical(label_map[Y_test_all_attacks[idx]], len(labels))\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_test[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(label_map[Y_test_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        if labels == [0,1] or labels ==[2,3]:\n",
    "            data = X_test_reduced[idx], np_utils.to_categorical(Y_test_all_attacks[idx], nb_classes)\n",
    "        else:\n",
    "            dimesnion_reduced = pca.fit_transform(X_test[idx])\n",
    "            data = dimesnion_reduced, np_utils.to_categorical(Y_test_all_attacks[idx], nb_classes)\n",
    "        validation_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import keras.backend as K\n",
    "import keras.activations as activations\n",
    "\n",
    "output_mask = tf.Variable(tf.zeros(output_dim), name=\"mask\", trainable=False)\n",
    "\n",
    "def masked_softmax(logits):\n",
    "    # logits are [batch_size, output_dim]\n",
    "    x = select(tf.tile(tf.equal(output_mask[None, :], 1.0), [tf.shape(logits)[0], 1]), logits, -1e32 * tf.ones_like(logits))\n",
    "    return activations.softmax(x)\n",
    "\n",
    "def set_active_outputs(labels):\n",
    "    new_mask = np.zeros(output_dim)\n",
    "    for l in labels:\n",
    "        new_mask[l] = 1.0\n",
    "    sess.run(output_mask.assign(new_mask))\n",
    "    print(sess.run(output_mask))\n",
    "    \n",
    "def masked_predict(model, data, targets):\n",
    "    pred = model.predict(data)\n",
    "    print(pred)\n",
    "    acc = np.argmax(pred,1)==np.argmax(targets,1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn, input_shape=(input_dim,)))\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn))\n",
    "#model.add(Dense(n_hidden_units, activation=activation_fn))\n",
    "model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax))\n",
    "\n",
    "from pathint import protocols\n",
    "from pathint.optimizers import KOOptimizer\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.callbacks import Callback\n",
    "from pathint.keras_utils import LossHistory\n",
    "\n",
    "#protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "#protocol_name, protocol = protocols.FISHER_PROTOCOL('sum')\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#opt = SGD(1e-3)\n",
    "#opt = RMSprop(lr=1e-3)\n",
    "oopt = KOOptimizer(opt, model=model, **protocol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=oopt, metrics=['accuracy'])\n",
    "model.model._make_train_function()\n",
    "saved_weights = model.get_weights()\n",
    "\n",
    "history = LossHistory()\n",
    "callbacks = [history]\n",
    "datafile_name = \"split_mnist_data_%s.pkl.gz\"%protocol_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step_updates': [('grads2', <function <lambda>.<locals>.<lambda> at 0x7f37d4528048>)], 'regularizer_fn': <function quadratic_regularizer at 0x7f37da7a38c8>, 'init_updates': [('cweights', <function <lambda>.<locals>.<lambda> at 0x7f37da7a3d08>)], 'task_updates': [('omega', <function <lambda>.<locals>.<lambda> at 0x7f37d45289d8>), ('cweights', <function <lambda>.<locals>.<lambda> at 0x7f37d4528a60>), ('grads2', <function <lambda>.<locals>.<lambda> at 0x7f37d4528ae8>)]}\n"
     ]
    }
   ],
   "source": [
    "print(protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_fits(cvals, training_data, valid_data, eval_on_train_set=False, nstats=1):\n",
    "    acc_mean = dict()\n",
    "    acc_std = dict()\n",
    "    model_weights_save = []   #Empty list to save the model weights aftertraining each task\n",
    "    for cidx, cval_ in enumerate(tqdm(cvals)):\n",
    "        runs = []\n",
    "        for runid in range(nstats):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # model.set_weights(saved_weights)\n",
    "            cstuffs = []\n",
    "            evals = []\n",
    "            print(\"setting cval\")\n",
    "            cval = cval_\n",
    "            oopt.set_strength(cval)\n",
    "            oopt.init_task_vars()\n",
    "            print(\"cval is\", sess.run(oopt.lam))\n",
    "            for age, tidx in enumerate(range(n_tasks)):\n",
    "                print(\"Age %i, cval is=%f\"%(age,cval))\n",
    "                print(\"settint output mask\")\n",
    "                set_active_outputs(task_labels[age])\n",
    "                stuffs = model.fit(training_data[tidx][0], training_data[tidx][1], batch_size, epochs_per_task, callbacks=callbacks)\n",
    "                oopt.update_task_metrics(training_data[tidx][0], training_data[tidx][1], batch_size)\n",
    "                oopt.update_task_vars()\n",
    "                ftask = []\n",
    "                model_weights_save.append(model.get_weights()) #Save the model weights aftertraining each task\n",
    "                for j in range(n_tasks):\n",
    "                    set_active_outputs(task_labels[j])\n",
    "                    if eval_on_train_set:\n",
    "                        f_ = masked_predict(model, training_data[j][0], training_data[j][1])\n",
    "                    else:\n",
    "                        f_ = masked_predict(model, valid_data[j][0], valid_data[j][1])\n",
    "                    ftask.append(np.mean(f_))\n",
    "                evals.append(ftask)\n",
    "                cstuffs.append(stuffs)\n",
    "\n",
    "                # Re-initialize optimizater variables\n",
    "                if reset_optimizer:\n",
    "                    oopt.reset_optimizer()\n",
    "\n",
    "            evals = np.array(evals)\n",
    "            runs.append(evals)\n",
    "        \n",
    "        runs = np.array(runs)\n",
    "        acc_mean[cval_] = runs.mean(0)\n",
    "        acc_std[cval_] = runs.std(0)\n",
    "    return dict(mean=acc_mean, std=acc_std),model_weights_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "# cvals = np.concatenate(([0], np.logspace(-2, 2, 10)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-1, 2, 2)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-2, 0, 3)))\n",
    "#cvals = np.logspace(-3, 3, 7)#[0, 1.0, 2, 5, 10]\n",
    "cvals = [1.0]\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 1.0\n",
      "Age 0, cval is=1.000000\n",
      "settint output mask\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "422/422 [==============================] - 0s - loss: 0.6903 - acc: 0.7725     \n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 0s - loss: 0.6795 - acc: 0.8957     \n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 0s - loss: 0.6616 - acc: 0.8957     \n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 0s - loss: 0.6310 - acc: 0.8957     \n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 0s - loss: 0.5807 - acc: 0.8957     \n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 0s - loss: 0.5120 - acc: 0.8957     \n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 0s - loss: 0.4372 - acc: 0.8957     \n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 0s - loss: 0.3798 - acc: 0.8957     \n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 0s - loss: 0.3542 - acc: 0.8957     \n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 0s - loss: 0.3459 - acc: 0.8957     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Age 1, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.1830 - acc: 0.9263     \n",
      "Epoch 2/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0913 - acc: 0.9625     \n",
      "Epoch 3/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0868 - acc: 0.9653     \n",
      "Epoch 4/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0844 - acc: 0.9655     \n",
      "Epoch 5/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0834 - acc: 0.9669     \n",
      "Epoch 6/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0829 - acc: 0.9670     \n",
      "Epoch 7/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0825 - acc: 0.9672     \n",
      "Epoch 8/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0815 - acc: 0.9671     \n",
      "Epoch 9/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0802 - acc: 0.9678     \n",
      "Epoch 10/10\n",
      "40496/40496 [==============================] - 1s - loss: 0.0795 - acc: 0.9682     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Age 2, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Epoch 1/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.1407 - acc: 0.9541     \n",
      "Epoch 2/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0573 - acc: 0.9847     \n",
      "Epoch 3/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0517 - acc: 0.9853     \n",
      "Epoch 4/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0483 - acc: 0.9853     \n",
      "Epoch 5/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0466 - acc: 0.9855     \n",
      "Epoch 6/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0450 - acc: 0.9857     \n",
      "Epoch 7/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0437 - acc: 0.9856     \n",
      "Epoch 8/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0429 - acc: 0.9859     \n",
      "Epoch 9/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0423 - acc: 0.9858     \n",
      "Epoch 10/10\n",
      "24933/24933 [==============================] - 0s - loss: 0.0415 - acc: 0.9861     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "Age 3, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Epoch 1/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5121 - acc: 0.7294     \n",
      "Epoch 2/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5039 - acc: 0.7307     \n",
      "Epoch 3/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5027 - acc: 0.7334     \n",
      "Epoch 4/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5007 - acc: 0.7364     \n",
      "Epoch 5/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5008 - acc: 0.7330     \n",
      "Epoch 6/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5004 - acc: 0.7326     \n",
      "Epoch 7/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5007 - acc: 0.7294     \n",
      "Epoch 8/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5003 - acc: 0.7315     \n",
      "Epoch 9/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5010 - acc: 0.7298     \n",
      "Epoch 10/10\n",
      "15221/15221 [==============================] - 0s - loss: 0.5003 - acc: 0.7350     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "Age 4, cval is=1.000000\n",
      "settint output mask\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Epoch 1/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6951 - acc: 0.4952     \n",
      "Epoch 2/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6933 - acc: 0.5333     \n",
      "Epoch 3/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6874 - acc: 0.5373     \n",
      "Epoch 4/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6852 - acc: 0.5302     \n",
      "Epoch 5/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6851 - acc: 0.5437     \n",
      "Epoch 6/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6857 - acc: 0.5540     \n",
      "Epoch 7/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6837 - acc: 0.5357     \n",
      "Epoch 8/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6853 - acc: 0.5373     \n",
      "Epoch 9/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6845 - acc: 0.5460     \n",
      "Epoch 10/10\n",
      "1260/1260 [==============================] - 0s - loss: 0.6830 - acc: 0.5413     \n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:38<00:00, 38.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "recompute_data = True\n",
    "\n",
    "if recompute_data:\n",
    "    data,model_weights_save = run_fits(cvals, training_datasets, validation_datasets, eval_on_train_set=False, nstats=n_stats)\n",
    "    utils.save_zipped_pickle(data, datafile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 35)                1260      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                1260      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                360       \n",
      "=================================================================\n",
      "Total params: 2,880\n",
      "Trainable params: 2,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(35, 35)\n",
      "(35,)\n",
      "(35, 35)\n",
      "(35,)\n",
      "(35, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(model.summary())\n",
    "model.save_weights('saved_weights.h5') #This file cannot be opend normaly to view the weghts. It can be loaded through load_model() or can be opend via hdf5 viewer\n",
    "\n",
    "#Shape of the array containg model weights\n",
    "a_list = model.get_weights()\n",
    "for i in range(len(a_list)):\n",
    "    print((np.array(a_list[i])).shape)\n",
    "\n",
    "#a_list[0][0][0] = a_list[0][0][0]+0.00001\n",
    "#print(a_list[0][0][0])\n",
    "#model.set_weights(a_list)\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_zipped_pickle(datafile_name)\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': {1.0: array([[0.89707047, 0.84220421, 0.25354049, 0.28013229, 0.45595302],\n",
      "       [0.89707047, 0.86844836, 0.69424584, 0.31346781, 0.45808863],\n",
      "       [0.89707047, 0.72081936, 0.81632408, 0.40300502, 0.46609717],\n",
      "       [0.89707047, 0.71442752, 0.81690843, 0.39384979, 0.46609717],\n",
      "       [0.89707047, 0.71378081, 0.81677093, 0.39382789, 0.46876668]])}, 'std': {1.0: array([[0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0.]])}}\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "#data = {'std': {1.0: array([[2.22044605e-16, 3.13642886e-01, 1.71893003e-01, 2.26736652e-01,\n",
    "#        3.04786159e-02],\n",
    "#       [2.22044605e-16, 4.07987673e-02, 2.55610650e-01, 2.00410541e-01,\n",
    "#        3.49696572e-02],\n",
    "#       [1.33254157e-01, 3.73764323e-02, 2.10062400e-01, 1.97353056e-01,\n",
    "#        3.87762069e-02],\n",
    "#       [2.22044605e-16, 3.83876679e-02, 1.99069189e-01, 1.01911121e-04,\n",
    "#        3.49696572e-02],\n",
    "#       [2.22044605e-16, 3.81488638e-02, 2.01397962e-01, 1.05063276e-04,\n",
    "#        5.41879087e-02]])}, 'mean': {1.0: array([[0.89707047, 0.63688319, 0.42490375, 0.5462952 , 0.48972237],\n",
    "#       [0.89707047, 0.84398039, 0.48918259, 0.5862365 , 0.50096103],\n",
    "#       [0.85265241, 0.84517002, 0.40773408, 0.57992422, 0.50355045],\n",
    "#       [0.89707047, 0.84484968, 0.31816651, 0.73128984, 0.50096103],\n",
    "#       [0.89707047, 0.8449339 , 0.31560566, 0.73128545, 0.47995195]])}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.colors as colors\n",
    "cmap = plt.get_cmap('cool') \n",
    "cNorm  = colors.Normalize(vmin=-5, vmax=np.log(np.max(list(data['mean'].keys()))))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "print(scalarMap.get_clim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x180 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(14, 2.5))\n",
    "axs = [subplot(1,n_tasks+1,1)]#, None, None]\n",
    "for i in range(1, n_tasks + 1):\n",
    "    axs.append(subplot(1, n_tasks+1, i+1, sharex=axs[0], sharey=axs[0]))\n",
    "    \n",
    "keys = list(data['mean'].keys())\n",
    "sorted_keys = np.sort(keys)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "        colorVal = scalarMap.to_rgba(np.log(cval))\n",
    "        # axs[j].plot(evals[:, j], c=colorVal)\n",
    "        axs[j].errorbar(range(n_tasks), mean_vals[:, j], yerr=std_vals[:, j]/np.sqrt(n_stats), c=colorVal)\n",
    "    label = \"c=%g\"%cval\n",
    "    average = mean_vals.mean(1)  #Taking the average of cross validation accuracies accross all tasks after learning each task\n",
    "    axs[-1].plot(average, c=colorVal, label=label)\n",
    "    \n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title((['task %d'%j for j in range(n_tasks)] + ['average'])[i])\n",
    "gcf().tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig('2Attack_Accuracy_10task.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89707047 0.89707047 0.89707047 0.89707047 0.89707047] [0. 0. 0. 0. 0.]\n",
      "[0.84220421 0.86844836 0.72081936 0.71442752 0.71378081] [0. 0. 0. 0. 0.]\n",
      "[0.25354049 0.69424584 0.81632408 0.81690843 0.81677093] [0. 0. 0. 0. 0.]\n",
      "[0.28013229 0.31346781 0.40300502 0.39384979 0.39382789] [0. 0. 0. 0. 0.]\n",
      "[0.45595302 0.45808863 0.46609717 0.46609717 0.46876668] [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "       print(mean_vals[:, j],std_vals[:, j]/np.sqrt(n_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "\n",
    "def simple_axis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 237.6x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fractional Correctness = Average of cross validation accuracies of learned tasks only after training each task \n",
    "fig = plt.figure(figsize=(3.3,2.5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_stuff = []\n",
    "    std_stuff = []\n",
    "    for i in range(len(data['mean'][cval])):\n",
    "        mean_stuff.append(data['mean'][cval][i][:i+1].mean())\n",
    "        std_stuff.append(np.sqrt((data['std'][cval][i][:i+1]**2).sum())/(n_stats*np.sqrt(n_stats)))\n",
    "    # plot(range(1,n_tasks+1), mean_stuff, 'o-', label=\"c=%g\"%cval)\n",
    "    errorbar(range(1,n_tasks+1), mean_stuff, yerr=std_stuff, fmt='o-', label=\"c=%g\"%cval)\n",
    "        \n",
    "axhline(data['mean'][cval][0][0], linestyle='--', color='k')\n",
    "xlabel('Number of tasks')\n",
    "ylabel('Fraction correct')\n",
    "legend(loc='best')\n",
    "xlim(0.5, 5.5)\n",
    "ylim(0.4, 1.02)\n",
    "# grid('on')\n",
    "# sns.despine()\n",
    "simple_axis(ax)\n",
    "plt.savefig('2attack_fractional_correct_increasing.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of data for task-0 of shape-(422, 35) is: 30\n",
      "----------------------------------------------------------------------\n",
      "Rank of data for task-1 of shape-(40496, 35) is: 35\n",
      "----------------------------------------------------------------------\n",
      "Rank of data for task-2 of shape-(24933, 35) is: 35\n",
      "----------------------------------------------------------------------\n",
      "Rank of data for task-3 of shape-(15221, 35) is: 35\n",
      "----------------------------------------------------------------------\n",
      "Rank of data for task-4 of shape-(1260, 35) is: 35\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#After Reducng dataset\n",
    "for j in range(n_tasks):\n",
    "    print('Rank of data for task-{0} of shape-{1} is: {2}'.format(j,training_datasets[j][0].shape,matrix_rank(np.matrix(training_datasets[j][0], dtype='float'))))\n",
    "    print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
