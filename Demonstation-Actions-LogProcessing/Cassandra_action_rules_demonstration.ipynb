{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"cassandra\" created\n",
      "\n",
      "deployment.apps \"cassandra\" autoscaled\n",
      "\n",
      "Starting OpenBSD Secure Shell server: sshd.\n",
      "\n",
      "deployment.apps \"pod-test1\" created\n",
      "\n",
      "deployment.apps \"pod-test2\" created\n",
      "\n",
      "deployment.apps \"pod-test3\" created\n",
      "\n",
      "deployment.apps \"pod-test4\" created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "import paramiko\n",
    "\n",
    "def run_linux_command(command):\n",
    "    p = subprocess.Popen(command, universal_newlines=True, shell=True, \n",
    "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    text = p.stdout.read()\n",
    "    retcode = p.wait()\n",
    "    return text\n",
    "\n",
    "def list_activepods(podtype):\n",
    "    cassandra_active_pods = {}\n",
    "    pods = run_linux_command('kubectl get pods | grep ' + podtype).split('\\n')\n",
    "    for pod in pods:\n",
    "        pod = pod.split(' ')[0]\n",
    "        ifconfig_content = run_linux_command('kubectl exec -it '+pod+' ifconfig')\n",
    "        ifconfig_content = ifconfig_content.split('\\n')\n",
    "        for ifconfig in ifconfig_content:\n",
    "            if 'inet' in ifconfig:\n",
    "                pod_ip = (ifconfig.strip().split(' ')[1])\n",
    "                cassandra_active_pods[pod] = pod_ip\n",
    "                break\n",
    "    return cassandra_active_pods\n",
    "\n",
    "cassandra_pods = {}\n",
    "cassandra_active_pods = {}\n",
    "user_pods = {}\n",
    "user_active_pods ={}\n",
    "os.chdir('/root/cassandra-stress')\n",
    "print(run_linux_command('kubectl create -f cassandra.yaml'))\n",
    "time.sleep(2)\n",
    "print(run_linux_command('kubectl autoscale deployment cassandra --min=2 --max=3 --cpu-percent=80'))\n",
    "podname = run_linux_command('kubectl get pods | grep cassandra').split(' ')[0]\n",
    "parent_started_pod = podname\n",
    "print(run_linux_command('kubectl exec '+ podname +' service ssh start'))\n",
    "print(run_linux_command('kubectl create -f pod_test1.yaml')) \n",
    "print(run_linux_command('kubectl create -f pod_test2.yaml'))\n",
    "print(run_linux_command('kubectl create -f pod_test3.yaml'))\n",
    "print(run_linux_command('kubectl create -f pod_test4.yaml'))\n",
    "ifconfig_content = run_linux_command('kubectl exec -it '+podname+' ifconfig')\n",
    "ifconfig_content = ifconfig_content.split('\\n')\n",
    "for ifconfig in ifconfig_content:\n",
    "    if 'inet' in ifconfig:\n",
    "        pod_ip = (ifconfig.strip().split(' ')[1])\n",
    "        break\n",
    "cassandra_pods[podname] = pod_ip\n",
    "\n",
    "users=[]\n",
    "for user in run_linux_command('kubectl exec '+parent_started_pod+' cat /etc/passwd | grep test').strip().split('\\n'):\n",
    "    users.append(user.split(':')[0])    \n",
    "users_thread_history={}\n",
    "for user in users:\n",
    "    users_thread_history[user] = []\n",
    "disabled_users = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subprocess.Popen object at 0x7f36608b3b70>\n",
      "<subprocess.Popen object at 0x7f36608b3ac8>\n",
      "Starting OpenBSD Secure Shell server: sshd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Autoscaling\n",
    "print(subprocess.Popen([\"kubectl\", \"exec\" , parent_started_pod, \"cassandra-stress\", \"write\", \"n=10000\"], stdout=subprocess.PIPE))\n",
    "\n",
    "cassandra_active_pods = list_activepods('cassandra')   \n",
    "if len(cassandra_pods) < len(cassandra_active_pods):\n",
    "    iterations = list(set(cassandra_active_pods.keys()) - set(cassandra_pods.keys()))\n",
    "    for podname in iterations:\n",
    "        print(subprocess.Popen([\"kubectl\", \"exec\" , podname, \"cassandra-stress\", \"write\", \"n=10000\"], stdout=subprocess.PIPE))\n",
    "        print(run_linux_command('kubectl exec '+ podname +' service ssh start'))\n",
    "        cassandra_pods[podname] = cassandra_active_pods[podname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request will be served from cassandra-7bb5c6cf9b-6hmv2 because CPU usage= 0.67 %\n",
      "test1 : cassandra-stress read n=1000 -rate threads=50\n",
      "Request will be served from cassandra-7bb5c6cf9b-c8f48 because CPU usage= 1.76 %\n",
      "test2 : cassandra-stress read n=1000 -rate threads=50\n",
      "Request will be served from cassandra-7bb5c6cf9b-c8f48 because CPU usage= 4.39 %\n",
      "test3 : cassandra-stress read n=1000 -rate threads=50\n",
      "Request will be served from cassandra-7bb5c6cf9b-6hmv2 because CPU usage= 0.61 %\n",
      "test4 : cassandra-stress read n=1000 -rate threads=50\n"
     ]
    }
   ],
   "source": [
    "#Load distribution after autoscaling\n",
    "for user in users:\n",
    "    cassandra_pods_CPUusage={}\n",
    "    for podname in cassandra_pods.keys():\n",
    "        try:\n",
    "            container_id = run_linux_command('kubectl get pods '+podname+' -o yaml | grep containerID').split('//')[1]\n",
    "            cpu_usage = (float(run_linux_command(\"docker stats \"+ container_id.strip() + \" --no-stream | awk 'FNR == 2 {print $3}'\").strip()[:-1]))\n",
    "            cassandra_pods_CPUusage[podname] = cpu_usage\n",
    "        except:\n",
    "            pass\n",
    "    selected_pod = ''\n",
    "    for podname in cassandra_pods_CPUusage.keys():\n",
    "        if cassandra_pods_CPUusage[podname] > 30:\n",
    "            pass\n",
    "        else:\n",
    "            selected_pod = podname\n",
    "            print('Request will be served from {0} because CPU usage= {1} %'.format(selected_pod,cassandra_pods_CPUusage[podname]))\n",
    "            break\n",
    "\n",
    "    if selected_pod != '':\n",
    "        command=run_linux_command('kubectl exec ' + parent_started_pod + ' cat /home/'+user+'/cassandra-command')\n",
    "        ssh = paramiko.SSHClient()\n",
    "        ssh.load_system_host_keys()\n",
    "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        ssh.connect(cassandra_pods[parent_started_pod], username=user, password=user)\n",
    "        ssh.exec_command('echo \"\" > /home/'+user+'/cassandra-command')\n",
    "\n",
    "        command = command.replace('\\n',\"\")\n",
    "        print(user ,':', command)\n",
    "        if command.startswith('cassandra-stress read n='):\n",
    "            ssh = paramiko.SSHClient()\n",
    "            ssh.load_system_host_keys()\n",
    "            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "            ssh.connect(cassandra_pods[selected_pod], username=user, password=user)\n",
    "            ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(command)\n",
    "            time.sleep(5)\n",
    "    else:\n",
    "        print('The server is busy. {0} your request couldn\\'t be fulfilled.'.format(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request will be served from cassandra-7bb5c6cf9b-c8f48 because CPU usage= 0.46 %\n",
      "test1 : cassandra-stress read n=1000 -rate threads=10 \n",
      "\n",
      "Currently all servers are busy. Your request is fulfilled with lower value of thread rate.\n",
      "Your request will be served from cassandra-7bb5c6cf9b-c8f48.Your command is: cassandra-stress read n=1000 -rate threads=30. \n",
      "\n",
      "Your request is fulfilled as --> test2 : cassandra-stress read n=1000 -rate threads=5 \n",
      "\n",
      "Currently all servers are busy. Your request is fulfilled with lower value of thread rate.\n",
      "Your request will be served from cassandra-7bb5c6cf9b-c8f48.Your command is: cassandra-stress read n=5000 -rate threads=60. \n",
      "\n",
      "Your request is fulfilled as --> test3 : cassandra-stress read n=5000 -rate threads=5 \n",
      "\n",
      "Request will be served from cassandra-7bb5c6cf9b-6hmv2 because CPU usage= 0.59 %\n",
      "test4 : cassandra-stress read n=7000 -rate threads=90 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Priority defining and resource limitting\n",
    "premium_users=['test2','test3']\n",
    "normal_users=list(set(users) - set(premium_users))\n",
    "for user in users:\n",
    "    cassandra_pods_CPUusage={}\n",
    "    for podname in cassandra_pods.keys():\n",
    "        try:\n",
    "            container_id = run_linux_command('kubectl get pods '+podname+' -o yaml | grep containerID').split('//')[1]\n",
    "            cpu_usage = (float(run_linux_command(\"docker stats \"+ container_id.strip() + \" --no-stream | awk 'FNR == 2 {print $3}'\").strip()[:-1]))\n",
    "            cassandra_pods_CPUusage[podname] = cpu_usage\n",
    "        except:\n",
    "            pass\n",
    "    selected_pod = ''\n",
    "    for podname in cassandra_pods_CPUusage.keys():\n",
    "        if cassandra_pods_CPUusage[podname] > 30:\n",
    "            pass\n",
    "        else:\n",
    "            selected_pod = podname\n",
    "            print('Request will be served from {0} because CPU usage= {1} %'.format(selected_pod,cassandra_pods_CPUusage[podname]))\n",
    "            break\n",
    "    \n",
    "    command=run_linux_command('kubectl exec ' + parent_started_pod + ' cat /home/'+user+'/cassandra-command')\n",
    "    command = command.replace('\\n',\"\")\n",
    "    if selected_pod != '':\n",
    "        print(user ,':', command,'\\n')\n",
    "        if command.startswith('cassandra-stress read n='):\n",
    "            ssh = paramiko.SSHClient()\n",
    "            ssh.load_system_host_keys()\n",
    "            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "            ssh.connect(cassandra_pods[selected_pod], username=user, password=user)\n",
    "            ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(command)\n",
    "            time.sleep(2)\n",
    "    else:\n",
    "        selected_pod = list(cassandra_pods_CPUusage.keys())[list(cassandra_pods_CPUusage.values()).index(min(cassandra_pods_CPUusage.values()))]\n",
    "        if user in premium_users:\n",
    "            print('Currently all servers are busy. Your request is fulfilled with lower value of thread rate.')\n",
    "            print('Your request will be served from {0}.Your command is: {1}. \\n'.format(selected_pod,command))\n",
    "            if command.startswith('cassandra-stress read n='):\n",
    "                ssh = paramiko.SSHClient()\n",
    "                ssh.load_system_host_keys()\n",
    "                ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "                ssh.connect(cassandra_pods[selected_pod], username=user, password=user)\n",
    "                command = command.split('threads=')[0]+'threads='+str(5)\n",
    "                ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(command)\n",
    "                print('Your request is fulfilled as -->',user ,':', command,'\\n')\n",
    "                time.sleep(2)\n",
    "        else:\n",
    "            print('The server is busy. {0} your request couldn\\'t be fulfilled. You are normal user. Apply for premium subscription.'.format(user))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request will be served from cassandra-7bb5c6cf9b-56knn because CPU usage= 2.56 %\n",
      "test1 : cassandra-stress read n=5000 -rate threads=10 \n",
      "\n",
      "Request will be served from cassandra-7bb5c6cf9b-krlvt because CPU usage= 0.45 %\n",
      "test2 : cassandra-stress read n=3000 -rate threads=30 \n",
      "\n",
      "User test3 has violated the thread limit. Disabling him.\n",
      "test3 : You have been blocked due to violating the thread limit.\n",
      "User test4 has violated the thread limit. Disabling him.\n",
      "test4 : You have been blocked due to violating the thread limit.\n"
     ]
    }
   ],
   "source": [
    "#Disable the pod\n",
    "imposed_thread_limit = 50\n",
    "imposed_thread_violate_window = 4\n",
    "violation=0\n",
    "premium_users=['test2','test3']\n",
    "normal_users=list(set(users) - set(premium_users))\n",
    "\n",
    "\n",
    "for user in users:\n",
    "    if len(users_thread_history[user]) >= imposed_thread_violate_window:\n",
    "        for i in range(1,imposed_thread_violate_window+1):\n",
    "            if users_thread_history[user][-i] >= imposed_thread_limit:\n",
    "                violation = violation+1\n",
    "        if violation == imposed_thread_violate_window:\n",
    "            print('User {0} has violated the thread limit. Disabling him.'.format(user))\n",
    "            violation = 0\n",
    "            disabled_users.append(user)\n",
    "   \n",
    "    if user not in disabled_users:\n",
    "        cassandra_pods_CPUusage={}\n",
    "        for podname in cassandra_pods.keys():\n",
    "            try:\n",
    "                container_id = run_linux_command('kubectl get pods '+podname+' -o yaml | grep containerID').split('//')[1]\n",
    "                cpu_usage = (float(run_linux_command(\"docker stats \"+ container_id.strip() + \" --no-stream | awk 'FNR == 2 {print $3}'\").strip()[:-1]))\n",
    "                cassandra_pods_CPUusage[podname] = cpu_usage\n",
    "            except:\n",
    "                pass\n",
    "        selected_pod = ''\n",
    "        for podname in cassandra_pods_CPUusage.keys():\n",
    "            if cassandra_pods_CPUusage[podname] > 30:\n",
    "                pass\n",
    "            else:\n",
    "                selected_pod = podname\n",
    "                print('Request will be served from {0} because CPU usage= {1} %'.format(selected_pod,cassandra_pods_CPUusage[podname]))\n",
    "                break\n",
    "\n",
    "        command=run_linux_command('kubectl exec ' + parent_started_pod + ' cat /home/'+user+'/cassandra-command')\n",
    "        command = command.replace('\\n',\"\")\n",
    "        users_thread_history[user].append(int(command.split('threads=')[1]))\n",
    "\n",
    "        if selected_pod != '':\n",
    "            print(user ,':', command,'\\n')\n",
    "            if command.startswith('cassandra-stress read n='):\n",
    "                ssh = paramiko.SSHClient()\n",
    "                ssh.load_system_host_keys()\n",
    "                ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "                ssh.connect(cassandra_pods[selected_pod], username=user, password=user)\n",
    "                ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(command)\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print('Command syntax is wrong.')\n",
    "        else:\n",
    "            selected_pod = list(cassandra_pods_CPUusage.keys())[list(cassandra_pods_CPUusage.values()).index(min(cassandra_pods_CPUusage.values()))]\n",
    "            if user in premium_users:\n",
    "                print('Currently all servers are busy. Your request is fulfilled with lower value of thread rate.')\n",
    "                print('Your request will be served from {0}.Your command is: {1}. \\n'.format(selected_pod,command))\n",
    "                if command.startswith('cassandra-stress read n='):\n",
    "                    ssh = paramiko.SSHClient()\n",
    "                    ssh.load_system_host_keys()\n",
    "                    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "                    ssh.connect(cassandra_pods[selected_pod], username=user, password=user)\n",
    "                    comand = command.split('threads=')[0]+'threads='+str(5)\n",
    "                    ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(command)\n",
    "                    print('Your request is fulfilled as -->',user ,':', command,'\\n')\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    print('Command syntax is wrong.')\n",
    "            else:\n",
    "                print('The server is busy. {0} your request couldn\\'t be fulfilled. You are normal user. Apply for premium subscription.'.format(user))\n",
    "    else:\n",
    "        print('{0} : You have been blocked due to violating the thread limit.'.format(user))\n",
    "        command=run_linux_command('kubectl exec ' + parent_started_pod + ' cat /home/'+user+'/cassandra-command')\n",
    "        command = command.replace('\\n',\"\")\n",
    "        users_thread_history[user].append(int(command.split('threads=')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test1': [10, 10, 10, 10, 10],\n",
       " 'test2': [30, 30, 30, 30, 30],\n",
       " 'test3': [60, 60, 60, 60, 60],\n",
       " 'test4': [100, 100, 100, 100, 100]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_thread_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "deployment.extensions \"pod-test3\" deleted\n",
      "\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n",
      "test3 has connected from IP: 172.17.0.9.\n",
      "172.17.0.9 belongs to pod: pod-test3-7857bc69cf-vvz5g\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-009cd88f1967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Can also be done by limiting the access. Steps are given at https://www.ostechnix.com/how-to-limit-users-access-to-the-linux-system/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mconnected_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_linux_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kubectl exec  '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mparent_started_pod\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' pinky'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mconnected_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnected_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mconnected_user\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconnected_users\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7aa831950548>\u001b[0m in \u001b[0;36mrun_linux_command\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m     12\u001b[0m     p = subprocess.Popen(command, universal_newlines=True, shell=True, \n\u001b[1;32m     13\u001b[0m     stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Delete the pod forever if he is forcefully messing up\n",
    "#Can also be done by limiting the access. Steps are given at https://www.ostechnix.com/how-to-limit-users-access-to-the-linux-system/\n",
    "while True:\n",
    "    connected_users = run_linux_command('kubectl exec  '+ parent_started_pod + ' pinky')\n",
    "    connected_users = connected_users.strip().split('\\n')\n",
    "    for connected_user in connected_users:\n",
    "        for disabled_user in list(set(disabled_users)):\n",
    "            if disabled_user in connected_user:\n",
    "                disabled_userIP = connected_user.split(' ')[-1]\n",
    "                print('{0} has connected from IP: {1}.'.format(disabled_user,disabled_userIP))\n",
    "                disabled_user_podname = run_linux_command('kubectl get pods -o wide | grep '+disabled_userIP)\n",
    "                disabled_user_podname = disabled_user_podname.strip().split(' ')[0]\n",
    "                print('{0} belongs to pod: {1}'.format(disabled_userIP,disabled_user_podname))\n",
    "                for deployment in run_linux_command('kubectl get deployments').strip().split('\\n'):\n",
    "                    for deploymentid in deployment.split(' '):\n",
    "                        if deploymentid.startswith('pod') and deploymentid in disabled_user_podname:\n",
    "                            deploymentid = deploymentid.strip()\n",
    "                            print(run_linux_command('kubectl delete deployments '+deploymentid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syscalls collection started.\n",
      "Syscalls collection completed.\n",
      "No new syscalls appear for pod cassandra-7bb5c6cf9b-56knn. \n",
      " All the syscall are within ['0', '1', '13', '2', '202', '21', '228', '232', '270', '74', '3', '37', '4', '5', '72', '78', '8', '96']\n",
      "Syscalls collection started.\n",
      "Syscalls collection completed.\n",
      "Alert!!!!: 20 syscalls have newly appeared for pod cassandra-7bb5c6cf9b-krlvt. They are {'33', '14', '24', '44', '16', '7', '61', '204', '273', '20', '60', '28', '9', '15', '10', '45', '233', '186', '231', '55'}.\n"
     ]
    }
   ],
   "source": [
    "#Syscalls --> Alert to admin\n",
    "unique_cassandra_syscalls = ['0', '1', '13', '2', '202', '21', '228', '232', '270', '74', '3', '37', '4', '5', '72', '78', '8', '96']\n",
    "import fileinput\n",
    "import re\n",
    "import glob\n",
    "from multiprocessing import Process, Pipe\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "def grep(PAT, FILES):\n",
    "    returned_grep = []\n",
    "    for line in fileinput.input(glob.glob(FILES)):\n",
    "        if re.search(PAT, line):\n",
    "             returned_grep.append(line)\n",
    "    return returned_grep\n",
    "\n",
    "cassandra_containers = run_linux_command('docker ps --format \"{{.ID}}: {{.Names}}\" | grep k8s_cassandra').strip().split('\\n')\n",
    "cassandra_containerid = []\n",
    "for container in cassandra_containers:\n",
    "    cassandra_containerid.append(container.split(':')[0])\n",
    "\n",
    "def collect_syscalls(mpPipe):\n",
    "    # This will take a long time\n",
    "    print(\"Syscalls collection started.\")\n",
    "    with open('syscall_run_cmd.sh','w') as fl:\n",
    "        fl.write(\"perf record -e 'raw_syscalls:sys_enter' -g --exclude-perf -a  --call-graph dwarf,4096 -o sys_call_collected -G kubepods/\" + qosClass_type + \"/pod\"+poduid+ \"/\"+ container_longID)\n",
    "    os.system('sh syscall_run_cmd.sh')\n",
    "    mpPipe.send(\"Done\")\n",
    "    \n",
    "for container_name in cassandra_containerid:\n",
    "    container_longID = subprocess.check_output(['docker', 'inspect', '--format=\"{{.Id}}\"', container_name])\n",
    "    container_longID = ast.literal_eval(container_longID[:-1].decode(\"utf-8\") )\n",
    "    pod_name = run_linux_command(\"kubectl get pod -o jsonpath='{range .items[?(@.status.containerStatuses[].containerID==\\\"docker://\" + container_longID +\"\\\")]}{.metadata.name}{end}'\")\n",
    "    run_linux_command('kubectl get pods '+pod_name + ' -o yaml > pod_yamlfile')\n",
    "    qosClass_type = grep('qosClass','pod_yamlfile')\n",
    "    poduid = grep('uid','pod_yamlfile')\n",
    "    os.system('rm -rf pod_yamlfile')\n",
    "    qosClass_type = ''.join(qosClass_type)\n",
    "    qosClass_type = qosClass_type.lower()\n",
    "    if 'besteffort' in qosClass_type:\n",
    "        qosClass_type = 'besteffort'\n",
    "    else:\n",
    "        qosClass_type = 'burstable'\n",
    "    poduid = poduid[1].split(':')[1].strip() \n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=collect_syscalls, args=(child_conn,))\n",
    "    p.start()\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        os.system('pkill -f perf')\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(5)\n",
    "    print(\"Syscalls collection completed.\")\n",
    "    os.system('perf script -i sys_call_collected > sys_call_numbers')\n",
    "    \n",
    "    os.system('rm -rf syscall_run_cmd.sh')\n",
    "    os.system('rm -rf sys_call_collected')\n",
    "    \n",
    "    with open('sys_call_numbers', 'r') as fl:\n",
    "        content = fl.readlines()\n",
    "    os.system('rm -rf sys_call_numbers')\n",
    "    if len(content) > 5:\n",
    "        Syscalls_list = []\n",
    "        for i in range(len(content)):\n",
    "            try: \n",
    "                Syscalls_list.append((content[i].split('NR')[1]).split(' ')[1])\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        current_container_syscall = np.unique(Syscalls_list)\n",
    "        if len(set(current_container_syscall) - set(unique_cassandra_syscalls)) > 0:\n",
    "            print('Alert!!!!: {0} syscalls have newly appeared for pod {1}. They are {2}.'.format(len(set(current_container_syscall) - set(unique_cassandra_syscalls)), pod_name, set(current_container_syscall) - set(unique_cassandra_syscalls)))\n",
    "        else:\n",
    "            print('No new syscalls appear for pod {0}. \\n All the syscall are within {1}'.format(pod_name,unique_cassandra_syscalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pod cassandra-7bb5c6cf9b-2r4wp is normal. No action needed\n",
      "Pod cassandra-7bb5c6cf9b-krlvt has detected new package. It needs to go rollback. The detected new packages are: {'manpages', 'linux-libc-dev', 'libitm1', 'libc-dev-bin', 'libc6-dev', 'libasan3', 'libtsan0', 'libquadmath0', 'libcilkrts5', 'libgcc-6-dev', 'libubsan0', 'libgomp1', 'libisl15', 'libmpc3', 'cpp', 'libmpx2', 'liblsan0', 'libmpfr4', 'gcc-6', 'cpp-6', 'liblocale-gettext-perl', 'libcc1-0', 'binutils', 'libatomic1', 'libstdc++-6-dev', 'gcc'} \n",
      "\n",
      "pod \"cassandra-7bb5c6cf9b-krlvt\" deleted\n",
      "pod \"cassandra-7bb5c6cf9b-krlvt\" replaced\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rollback\n",
    "cassandra_pod_packagelist = ['adduser', 'apt', 'base-files', 'base-passwd', 'bash', 'bsdutils', 'bzip2', 'ca-certificates', 'ca-certificates-java', 'cassandra', 'cassandra-tools', 'cgmanager', 'coreutils', 'dash', 'dbus', 'debconf', 'debian-archive-keyring', 'debianutils', 'diffutils', 'dirmngr', 'dmsetup', 'dpkg', 'e2fslibs', 'e2fsprogs', 'file', 'findutils', 'fontconfig-config', 'fonts-dejavu-core', 'gcc-6-base', 'gnupg', 'gnupg-agent', 'gpgv', 'grep', 'gzip', 'hostname', 'init-system-helpers', 'iproute2', 'iputils-ping', 'java-common', 'krb5-locales', 'libacl1', 'libapparmor1', 'libapt-pkg5.0', 'libassuan0', 'libattr1', 'libaudit-common', 'libaudit1', 'libavahi-client3', 'libavahi-common-data', 'libavahi-common3', 'libblkid1', 'libbsd0', 'libbz2-1.0', 'libc-bin', 'libc6', 'libcap-ng0', 'libcap2', 'libcap2-bin', 'libcgmanager0', 'libcomerr2', 'libcryptsetup4', 'libcups2', 'libdb5.3', 'libdbus-1-3', 'libdebconfclient0', 'libdevmapper1.02.1', 'libedit2', 'libelf1', 'libexpat1', 'libfdisk1', 'libffi6', 'libfontconfig1', 'libfreetype6', 'libgcc1', 'libgcrypt20', 'libgdbm3', 'libglib2.0-0', 'libglib2.0-data', 'libgmp10', 'libgnutls30', 'libgpg-error0', 'libgpm2', 'libgssapi-krb5-2', 'libhogweed4', 'libicu57', 'libidn11', 'libip4tc0', 'libjemalloc1', 'libjpeg62-turbo', 'libk5crypto3', 'libkeyutils1', 'libkmod2', 'libkrb5-3', 'libkrb5support0', 'libksba8', 'liblcms2-2', 'libldap-2.4-2', 'libldap-common', 'liblz4-1', 'liblzma5', 'libmagic-mgc', 'libmagic1', 'libmnl0', 'libmount1', 'libncurses5', 'libncursesw5', 'libnettle6', 'libnih-dbus1', 'libnih1', 'libnpth0', 'libnspr4', 'libnss3', 'libopts25', 'libp11-kit0', 'libpam-cap', 'libpam-modules', 'libpam-modules-bin', 'libpam-runtime', 'libpam-systemd', 'libpam0g', 'libpcre3', 'libpcsclite1', 'libperl5.24', 'libpng16-16', 'libprocps6', 'libpython-stdlib', 'libpython2.7-minimal', 'libpython2.7-stdlib', 'libreadline7', 'libsasl2-2', 'libsasl2-modules-db', 'libseccomp2', 'libselinux1', 'libsemanage-common', 'libsemanage1', 'libsepol1', 'libsmartcols1', 'libsqlite3-0', 'libss2', 'libssl1.0.2', 'libssl1.1', 'libstdc++6', 'libsystemd0', 'libtasn1-6', 'libtinfo5', 'libudev1', 'libustr-1.0-1', 'libuuid1', 'libwrap0', 'libx11-6', 'libx11-data', 'libxau6', 'libxcb1', 'libxdmcp6', 'libxext6', 'libxi6', 'libxml2', 'libxmuu1', 'libxrender1', 'libxtst6', 'login', 'lsb-base', 'mawk', 'mime-support', 'mount', 'multiarch-support', 'ncurses-base', 'ncurses-bin', 'ncurses-term', 'net-tools', 'netbase', 'ntp', 'openjdk-8-jre-headless', 'openssh-client', 'openssh-server', 'openssh-sftp-server', 'openssl', 'passwd', 'perl', 'perl-base', 'perl-modules-5.24', 'pinentry-curses', 'procps', 'python', 'python-minimal', 'python2.7', 'python2.7-minimal', 'readline-common', 'rename', 'sed', 'sensible-utils', 'sgml-base', 'shared-mime-info', 'systemd', 'systemd-shim', 'sysvinit-utils', 'tar', 'tcpd', 'tzdata', 'ucf', 'util-linux', 'vim', 'vim-common', 'vim-runtime', 'x11-common', 'xauth', 'xdg-user-dirs', 'xml-core', 'xxd', 'xz-utils', 'zlib1g']\n",
    "\n",
    "for containerid in cassandra_containerid:\n",
    "    crawler_command = ['docker', 'run', '--rm', '--privileged', '--net=host', '--pid=host', '-v', '/cgroup:/cgroup:ro', '-v', '/sys/fs/cgroup:/sys/fs/cgroup:ro', '-v', '/var/lib/docker:/var/lib/docker:ro', '-v', '/var/run/docker.sock:/var/run/docker.sock', '-v', '-it', 'crawler', '--crawlmode', 'OUTCONTAINER', '--features', 'package', '--crawlContainers', containerid]\n",
    "    crawler_output = subprocess.check_output(crawler_command)\n",
    "    crawler_output = crawler_output.decode(\"utf-8\").split('\\n')\n",
    "\n",
    "    current_container_packages=[]\n",
    "    for i,record in enumerate(crawler_output):\n",
    "        if crawler_output[i].startswith('package'):\n",
    "            current_container_packages.append(ast.literal_eval(crawler_output[i].split('\\t')[1]))\n",
    "    \n",
    "    container_longID = subprocess.check_output(['docker', 'inspect', '--format=\"{{.Id}}\"', containerid])\n",
    "    container_longID = ast.literal_eval(container_longID[:-1].decode(\"utf-8\") )\n",
    "    pod_name = run_linux_command(\"kubectl get pod -o jsonpath='{range .items[?(@.status.containerStatuses[].containerID==\\\"docker://\" + container_longID +\"\\\")]}{.metadata.name}{end}'\")\n",
    "    \n",
    "    if len(set(current_container_packages) - set(cassandra_pod_packagelist)) > 0:\n",
    "        print('Pod {0} has detected new package. It needs to go rollback. The detected new packages are: {1} \\n'.format(pod_name,set(current_container_packages) - set(cassandra_pod_packagelist)))\n",
    "        print(run_linux_command('kubectl get pod ' + pod_name + ' -o yaml | kubectl replace --force -f -'))\n",
    "    elif len(set(cassandra_pod_packagelist) - set(current_container_packages)) > 0:\n",
    "        print('Pod {0} is missing few packages. It needs to go rollback. The missing packages are: {1} \\n'.format(pod_name,set(cassandra_pod_packagelist) - set(current_container_packages)))\n",
    "        print(run_linux_command('kubectl get pod ' + pod_name + ' -o yaml | kubectl replace --force -f -'))\n",
    "    else:\n",
    "        print('Pod {0} is normal. No action needed'.format(pod_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heap_size_formatting(max_heap):\n",
    "    if 'M' in max_heap:\n",
    "        max_heap = float(max_heap[:-1])\n",
    "    elif 'G' in max_heap:\n",
    "        max_heap = float(max_heap[:-1])*1024\n",
    "    elif 'K' in max_heap:\n",
    "        max_heap = float(max_heap[:-1])/1024\n",
    "    return(max_heap)\n",
    "\n",
    "test1pod = run_linux_command('kubectl get pods | grep test1').split(' ')[0]\n",
    "test2pod = run_linux_command('kubectl get pods | grep test2').split(' ')[0]\n",
    "#run_linux_command('ssh test1@'+pod_ip)\n",
    "import paramiko\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.load_system_host_keys()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "ssh.connect(pod_ip, username='test1', password='test1')\n",
    "training_frames = []\n",
    "for thread_count in range(5,100,10):\n",
    "    ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('cassandra-stress read n=2000 -rate threads='+str(thread_count))\n",
    "    #print(ssh_stdout.read())  #To display the output by running this comand.\n",
    "    line_start = 0\n",
    "    timeout = 10\n",
    "    import time\n",
    "    \n",
    "    while line_start == 0:\n",
    "        endtime = time.time() + timeout\n",
    "        while not ssh_stdout.channel.eof_received:\n",
    "            time.sleep(1)\n",
    "            if time.time() > endtime:\n",
    "                ssh_stdout.channel.close()\n",
    "                break\n",
    "        readrequest_stats = ssh_stdout.readlines()\n",
    "        \n",
    "        for i,line in enumerate(readrequest_stats):\n",
    "            if line.startswith('type       total ops,    op/s,    pk/s,   row/s'):\n",
    "                line_start = i\n",
    "                time.sleep(1)\n",
    "                break\n",
    "    \n",
    "    line_end = 0    \n",
    "    for i,line in enumerate(readrequest_stats[line_start:]):\n",
    "        if line.endswith('Results:'):\n",
    "            line_end = i\n",
    "            break\n",
    "\n",
    "    if line_end == 0:\n",
    "        line_end = len(readrequest_stats)\n",
    "\n",
    "    readrequest_extract = []\n",
    "    for record in readrequest_stats[line_start:line_end]:\n",
    "        readrequest_extract.append(record.split(','))\n",
    "\n",
    "    for i in range(len(readrequest_extract)):\n",
    "        for j in range(len(readrequest_extract[i])):\n",
    "            readrequest_extract[i][j] = readrequest_extract[i][j].strip()\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame.from_records(readrequest_extract[1:])\n",
    "    df.drop(0, axis=1, inplace=True)\n",
    "    readrequest_extract[0][0] = readrequest_extract[0][0][-9:]\n",
    "    df.columns = readrequest_extract[0]\n",
    "\n",
    "    df = df.convert_objects(convert_numeric=True)\n",
    "    readrequest_frame = []\n",
    "    for i in [1,4,5,6,7,8,9,11]:        \n",
    "        readrequest_frame.append(round(np.mean(df[df.columns[i]]),5))\n",
    "\n",
    "    for record in run_linux_command('cat etc/cassandra/cassandra-env.sh | grep MAX_HEAP_SIZE=').split('\\n'):\n",
    "        if record.startswith('MAX_HEAP_SIZE'):\n",
    "            max_heap = ast.literal_eval(record.split('=')[1])\n",
    "            max_heap = heap_size_formatting(max_heap)\n",
    "\n",
    "    for record in run_linux_command('cat etc/cassandra/cassandra-env.sh | grep HEAP_NEWSIZE=').split('\\n'):\n",
    "        if record.startswith('HEAP_NEWSIZE='):\n",
    "            new_heap = ast.literal_eval(record.split('=')[1])\n",
    "            new_heap = heap_size_formatting(new_heap)    \n",
    "\n",
    "    readrequest_frame.append(max_heap)\n",
    "    readrequest_frame.append(new_heap)\n",
    "    \n",
    "    pod_containerid = run_linux_command('kubectl get pods cassandra-575c848f7c-xl946 -o yaml | grep containerID').split('//')[1].strip()\n",
    "    pid_nums = float(run_linux_command(\"docker stats \"+pod_containerid+\" --no-stream | awk 'FNR == 2 {print $14}'\").strip())\n",
    "    readrequest_frame.append(pid_nums)\n",
    "    \n",
    "    print('thread_count=',thread_count)\n",
    "    training_frames.append(readrequest_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parse the CPU, process, metric, connection feature\n",
    "pod_containerid = 'fff5cc9ff1c4'\n",
    "crawler_command = ['docker', 'run', '--rm', '--privileged', '--net=host', '--pid=host', '-v', '/cgroup:/cgroup:ro', '-v', '/sys/fs/cgroup:/sys/fs/cgroup:ro', '-v', '/var/lib/docker:/var/lib/docker:ro', '-v', '/var/run/docker.sock:/var/run/docker.sock', '-v', '-it', 'crawler', '--crawlmode', 'OUTCONTAINER', '--features', 'cpu,metric,process,connection', '--crawlContainers', pod_containerid]\n",
    "crawler_output = subprocess.check_output(crawler_command)\n",
    "crawler_output = crawler_output.decode(\"utf-8\").split('\\n')\n",
    "\n",
    "dict_container_crawled = {}\n",
    "cpu_usage = []\n",
    "process_names = []\n",
    "connection_names = []\n",
    "metric_names = []\n",
    "\n",
    "for i,record in enumerate(crawler_output):\n",
    "    if crawler_output[i].startswith('cpu'):\n",
    "        cpu_usage.append(crawler_output[i].split('\\t')[2])\n",
    "\n",
    "    if crawler_output[i].startswith('process'):\n",
    "        process_names.append(crawler_output[i].split('\\t')[1])\n",
    "\n",
    "    if crawler_output[i].startswith('metric'):\n",
    "        metric_names.append(crawler_output[i].split('\\t')[2])\n",
    "\n",
    "    if crawler_output[i].startswith('connection'):\n",
    "        connection_names.append(crawler_output[i].split('\\t')[2])\n",
    "\n",
    "if ast.literal_eval(''.join(cpu_usage))['cpu_idle'] < 30:\n",
    "    if 'cassandra-stres' in ''.join(process_names):\n",
    "        agent_IPaddress = {}\n",
    "        java_pids = []\n",
    "        for record in connection_names:\n",
    "            connection_dict = record.replace('null','0')\n",
    "            connection_dict = ast.literal_eval(connection_dict)\n",
    "            if connection_dict['connstatus'] == 'ESTABLISHED':\n",
    "                if connection_dict['pname'] == 'sshd':\n",
    "                    agent_IPaddress[connection_dict['pid']] = [connection_dict['remoteipaddr']]\n",
    "\n",
    "                if connection_dict['pname'] == 'java':\n",
    "                    java_pids.append(connection_dict['pid'])\n",
    "    \n",
    "    if len(agent_IPaddress) > 0:\n",
    "        for key in agent_IPaddress.keys():\n",
    "            for record in metric_names:\n",
    "                metric = record.replace('null','0')\n",
    "                metric = ast.literal_eval(metric)\n",
    "                if metric['pid'] == key:\n",
    "                    agent_IPaddress[key].append(metric['user'])\n",
    "\n",
    "    cassandra_processdetails={}\n",
    "    if len(java_pids) > 0:\n",
    "        java_processdetails = {}\n",
    "        for record in metric_names:\n",
    "            metric = record.replace('null','0')\n",
    "            metric = ast.literal_eval(metric)\n",
    "            if metric['pname'] == 'java':\n",
    "                java_processdetails[metric['pid']] = [metric['cpupct'],metric['mempct']]\n",
    "                \n",
    "            if metric['pname'] == 'cassandra-stres':\n",
    "                cassandra_processdetails[metric['pid']] = metric['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('X=',np.array(training_frames))\n",
    "print('Y=',[i for i in range(5,100,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for iteration,filename in enumerate(filenames):\n",
    "    with open('/root/cassandra-stress/'+filename) as fl:\n",
    "        logs = fl.readlines()\n",
    "\n",
    "    thread_count = []\n",
    "    for line in logs:\n",
    "        if line.startswith('Running with '):\n",
    "            thread_count.append(int(line.split(' ')[2]))\n",
    "    #print thread_count\n",
    "    complete_frame = []\n",
    "    current_frame = []\n",
    "    for index,line in enumerate(logs):\n",
    "        if line.startswith('Results'):\n",
    "            for i in range(1,17):\n",
    "                extracted_part =  logs[index+i].split(':')[1].split('\\t')[0].lstrip().split(' ')[0]\n",
    "                if ',' in extracted_part: \n",
    "                    extracted_part = extracted_part.replace(',','')    \n",
    "                current_frame.append(float(extracted_part))\n",
    "            complete_frame.append(current_frame)\n",
    "            current_frame = []\n",
    "\n",
    "    complete_frame = pd.DataFrame(complete_frame)\n",
    "    complete_frame.columns = ['op-rate','partition-rate','row-rate','latency-mean','latency-median','latency-95p','latency-99p','latency-99.99p','latency-max','total-partition','total-errors','total-gc-count','total-memory','total-gc-time','avg-gc-time','stddev-gc-time']\n",
    "    complete_frame['heap-size'] = int(filename.split('_')[1].split('heap')[1][:-1]) * np.ones((len(complete_frame),1))\n",
    "    complete_frame['Maxheap-size'] = int(filename.split('_')[2].split('max')[1].split('M')[0]) * np.ones((len(complete_frame),1))\n",
    "    complete_frame['thread-count'] = thread_count\n",
    "    if iteration != 0:\n",
    "        complete_frame = pd.concat([lastiter_frame, complete_frame],ignore_index=True)\n",
    "    lastiter_frame = complete_frame    \n",
    "complete_frame.drop('total-partition', axis=1, inplace=True)\n",
    "\n",
    "for i in range(len(complete_frame['thread-count'])):\n",
    "    if complete_frame['thread-count'][i] < 20:\n",
    "        complete_frame['thread-count'][i] = 'Below 20'\n",
    "    elif complete_frame['thread-count'][i] >= 20 and complete_frame['thread-count'][i] < 50:\n",
    "        complete_frame['thread-count'][i] = '20-49'\n",
    "    elif complete_frame['thread-count'][i] >= 50 and complete_frame['thread-count'][i] < 100:\n",
    "        complete_frame['thread-count'][i] = '50-99'\n",
    "    elif complete_frame['thread-count'][i] >= 100 and complete_frame['thread-count'][i] < 300:\n",
    "        complete_frame['thread-count'][i] = '100-299'\n",
    "    elif complete_frame['thread-count'][i] >= 300 and complete_frame['thread-count'][i] < 600:\n",
    "        complete_frame['thread-count'][i] = '300-599'   \n",
    "    else:\n",
    "        complete_frame['thread-count'][i] = '600-and-above'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X=complete_frame.values[:,:-1]\n",
    "Y=complete_frame['thread-count']\n",
    "cleanup_nums = {'100-299':0, '20-49':1, '300-599':2, '50-99':3, '600-and-above':4, 'Below 20':5}\n",
    "Y.replace(cleanup_nums,inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logisticRegr = LogisticRegression(solver = 'liblinear',verbose=1)\n",
    "logisticRegr.fit(X_train,Y_train)\n",
    "score = logisticRegr.score(X_test , Y_test)\n",
    "print(score)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = logisticRegr.predict(X_test)\n",
    "cm = metrics.confusion_matrix(Y_test, predictions)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {:.3f}'.format(score) \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where\n",
    "\n",
    "# Data params\n",
    "input_dim = 17\n",
    "output_dim = 6\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 51\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 10\n",
    "epochs_per_task = 10\n",
    "\n",
    "n_stats = 10\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[7,9],[3,8],[0,6],[4,2]]\n",
    "#task_labels = [[8,9], [6,7], [4,5], [2,3], [0,1]]\n",
    "#task_labels = [[1,4], [0,9], [7,8], [3,6], [2,5]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8,9]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "task_labels = [[0,1], [2,3], [4,5]]\n",
    "n_tasks = len(task_labels)\n",
    "nb_classes  = 6\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_train, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_train[idx], np_utils.to_categorical(label_map[Y_train[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_train[idx], np_utils.to_categorical(Y_train[idx], nb_classes)\n",
    "        training_datasets.append(data)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_test, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_test[idx], np_utils.to_categorical(label_map[Y_test[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_test[idx], np_utils.to_categorical(Y_test[idx], nb_classes)\n",
    "        validation_datasets.append(data)\n",
    "        \n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import keras.backend as K\n",
    "import keras.activations as activations\n",
    "\n",
    "output_mask = tf.Variable(tf.zeros(output_dim), name=\"mask\", trainable=False)\n",
    "\n",
    "def masked_softmax(logits):\n",
    "    # logits are [batch_size, output_dim]\n",
    "    x = select(tf.tile(tf.equal(output_mask[None, :], 1.0), [tf.shape(logits)[0], 1]), logits, -1e32 * tf.ones_like(logits))\n",
    "    return activations.softmax(x)\n",
    "\n",
    "def set_active_outputs(labels):\n",
    "    new_mask = np.zeros(output_dim)\n",
    "    for l in labels:\n",
    "        new_mask[l] = 1.0\n",
    "    sess.run(output_mask.assign(new_mask))\n",
    "    sess.run(output_mask)\n",
    "    \n",
    "def masked_predict(model, data, targets):\n",
    "    pred = model.predict(data)\n",
    "    #print(pred)\n",
    "    acc = np.argmax(pred,1)==np.argmax(targets,1)\n",
    "    return acc.mean()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn, input_shape=(input_dim,)))\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn))\n",
    "#model.add(Dense(n_hidden_units, activation=activation_fn))\n",
    "model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax))\n",
    "\n",
    "from pathint import protocols\n",
    "from pathint.optimizers import KOOptimizer\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.callbacks import Callback\n",
    "from pathint.keras_utils import LossHistory\n",
    "from keras.callbacks import History \n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "#protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "#protocol_name, protocol = protocols.FISHER_PROTOCOL('sum')\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#opt = SGD(1e-3)\n",
    "#opt = RMSprop(lr=1e-3)\n",
    "oopt = KOOptimizer(opt, model=model, **protocol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=oopt, metrics=['accuracy'])\n",
    "model.model._make_train_function()\n",
    "saved_weights = model.get_weights()\n",
    "\n",
    "save_weights_epoch=[]\n",
    "save_loss_epoch=[]\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: save_weights_epoch.append(model.get_weights()))\n",
    "history = LossHistory()\n",
    "#history = History()\n",
    "callbacks = [history]\n",
    "datafile_name = \"split_mnist_data_%s.pkl.gz\"%protocol_name\n",
    "\n",
    "print(protocol)\n",
    "\n",
    "def run_fits(cvals, training_data, valid_data, eval_on_train_set=False, nstats=1):\n",
    "    acc_mean = dict()\n",
    "    acc_std = dict()\n",
    "    model_weights_save = []   #Empty list to save the model weights aftertraining each task\n",
    "    for cidx, cval_ in enumerate(tqdm(cvals)):\n",
    "        runs = []\n",
    "        for runid in range(nstats):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # model.set_weights(saved_weights)\n",
    "            cstuffs = []\n",
    "            evals = []\n",
    "            print(\"setting cval\")\n",
    "            cval = cval_\n",
    "            oopt.set_strength(cval)\n",
    "            oopt.init_task_vars()\n",
    "            print(\"cval is\", sess.run(oopt.lam))\n",
    "            for age, tidx in enumerate(range(n_tasks)):\n",
    "                print(\"Age %i, cval is=%f\"%(age,cval))\n",
    "                print(\"settint output mask\")\n",
    "                set_active_outputs(task_labels[age])\n",
    "                stuffs = model.fit(training_data[tidx][0], training_data[tidx][1], batch_size, epochs_per_task, callbacks=[print_weights])\n",
    "                save_loss_epoch.append(stuffs.history['loss'])\n",
    "                #if age != 0:\n",
    "                    #model_prune(age, unimportant_threshold = 5)\n",
    "                oopt.update_task_metrics(training_data[tidx][0], training_data[tidx][1], batch_size)\n",
    "                oopt.update_task_vars()\n",
    "                ftask = []\n",
    "                model_weights_save.append(model.get_weights()) #Save the model weights aftertraining each task\n",
    "                for j in range(n_tasks):\n",
    "                    set_active_outputs(task_labels[j])\n",
    "                    if eval_on_train_set:\n",
    "                        f_ = masked_predict(model, training_data[j][0], training_data[j][1])\n",
    "                    else:\n",
    "                        f_ = masked_predict(model, valid_data[j][0], valid_data[j][1])\n",
    "                    ftask.append(np.mean(f_))\n",
    "                evals.append(ftask)\n",
    "                cstuffs.append(stuffs)\n",
    "\n",
    "                # Re-initialize optimizater variables\n",
    "                if reset_optimizer:\n",
    "                    oopt.reset_optimizer()\n",
    "\n",
    "            evals = np.array(evals)\n",
    "            runs.append(evals)\n",
    "        \n",
    "        runs = np.array(runs)\n",
    "        acc_mean[cval_] = runs.mean(0)\n",
    "        acc_std[cval_] = runs.std(0)\n",
    "    return dict(mean=acc_mean, std=acc_std),model_weights_save\n",
    "\n",
    "cvals = [1.0]\n",
    "print(cvals)\n",
    "\n",
    "np.random.seed(0)\n",
    "recompute_data = True\n",
    "\n",
    "if recompute_data:\n",
    "    data,model_weights_save = run_fits(cvals, training_datasets, validation_datasets, eval_on_train_set=False, nstats=n_stats)\n",
    "    utils.save_zipped_pickle(data, datafile_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "print(model.summary())\n",
    "model.save_weights('saved_weights.h5') #This file cannot be opend normaly to view the weghts. It can be loaded through load_model() or can be opend via hdf5 viewer\n",
    "\n",
    "#Shape of the array containg model weights\n",
    "a_list = model.get_weights()\n",
    "for i in range(len(a_list)):\n",
    "    print((np.array(a_list[i])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = utils.load_zipped_pickle(datafile_name)\n",
    "print(cvals)\n",
    "for k in cvals:\n",
    "    for i in range(n_tasks):\n",
    "        for j in range(i):\n",
    "            data['mean'][k][j][i] = 0\n",
    "            data['std'][k][j][i] = 0\n",
    "        \n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "cmap = plt.get_cmap('cool') \n",
    "cNorm  = colors.Normalize(vmin=-5, vmax=np.log(np.max(list(data['mean'].keys()))))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "print(scalarMap.get_clim())\n",
    "\n",
    "figure(figsize=(2, 12))\n",
    "axs = [subplot(n_tasks+1,1,1)]#, None, None]\n",
    "for i in range(1, n_tasks + 1):\n",
    "    axs.append(subplot(n_tasks+1,1, i+1, sharex=axs[0], sharey=axs[0]))\n",
    "    \n",
    "keys = list(data['mean'].keys())\n",
    "sorted_keys = np.sort(keys)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "        colorVal = scalarMap.to_rgba(np.log(cval))\n",
    "        # axs[j].plot(evals[:, j], c=colorVal)\n",
    "        axs[j].errorbar(range(n_tasks), mean_vals[:, j], yerr=std_vals[:, j]/np.sqrt(n_stats), c=colorVal)\n",
    "    label = \"c=%g\"%cval\n",
    "    average = mean_vals.mean(1)  #Taking the average of cross validation accuracies accross all tasks after learning each task\n",
    "    axs[-1].plot(average, c=colorVal, label=label)\n",
    "    \n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title((['task %d'%j for j in range(n_tasks)] + ['average'])[i])\n",
    "gcf().tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
